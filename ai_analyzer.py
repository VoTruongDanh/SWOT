"""
AI Analyzer Module - X·ª≠ l√Ω ph√¢n t√≠ch SWOT b·∫±ng Gemini API
"""
import json
import os
import time
import pandas as pd
import google.generativeai as genai
from typing import Dict, List, Any
from dotenv import load_dotenv

# Load API Key t·ª´ Streamlit Secrets (khi deploy) ho·∫∑c .env (khi ch·∫°y local)
# Th·ª≠ ƒë·ªçc t·ª´ .env tr∆∞·ªõc (cho local development)
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# N·∫øu kh√¥ng c√≥ trong .env, th·ª≠ ƒë·ªçc t·ª´ Streamlit Secrets (khi deploy l√™n Streamlit Cloud)
if not GEMINI_API_KEY:
    try:
        import streamlit as st
        # Th·ª≠ ƒë·ªçc t·ª´ Streamlit Secrets
        if hasattr(st, 'secrets') and hasattr(st.secrets, 'get'):
            GEMINI_API_KEY = st.secrets.get('GEMINI_API_KEY', None)
    except:
        # N·∫øu kh√¥ng c√≥ streamlit ho·∫∑c kh√¥ng c√≥ secrets, gi·ªØ None
        pass

# C·∫•u h√¨nh Gemini API
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)


def build_system_prompt(analysis_level: str = 'enterprise') -> str:
    """
    X√¢y d·ª±ng System Prompt cho AI theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
    
    Args:
        analysis_level: 'basic', 'standard', ho·∫∑c 'enterprise'
    """
    
    base_prompt = """# ROLE (VAI TR√í)
B·∫°n l√† m·ªôt Chuy√™n gia Ph√¢n t√≠ch D·ªØ li·ªáu v√† Chi·∫øn l∆∞·ª£c Kinh doanh F&B (Data Analyst & Business Strategist) v·ªõi 20 nƒÉm kinh nghi·ªám. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc c√°c ƒë√°nh gi√° th√¥ (raw reviews), ph√¢n t√≠ch c·∫£m x√∫c, gom nh√≥m ch·ªß ƒë·ªÅ v√† x√¢y d·ª±ng m√¥ h√¨nh SWOT CHUY√äN S√ÇU c·∫•p doanh nghi·ªáp.

# INPUT DATA (D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO)
B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c m·ªôt danh s√°ch c√°c ƒë√°nh gi√° t·ª´ kh√°ch h√†ng v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin. M·ªói ƒë√°nh gi√° c√≥ th·ªÉ bao g·ªìm:
- "SOURCE: MY_SHOP": ƒê√°nh gi√° v·ªÅ qu√°n c·ªßa t√¥i.
- "SOURCE: COMPETITOR": ƒê√°nh gi√° v·ªÅ ƒë·ªëi th·ªß c·∫°nh tranh.
- "CONTENT": N·ªôi dung ƒë√°nh gi√° (b·∫Øt bu·ªôc)
- "PRICE": Gi√° c·∫£ (n·∫øu c√≥)
- "RATING": ƒêi·ªÉm ƒë√°nh gi√°/s·ªë sao (n·∫øu c√≥)
- "MENU_ITEM": T√™n m√≥n/s·∫£n ph·∫©m (n·∫øu c√≥)
- "DATE": Ng√†y ƒë√°nh gi√° (n·∫øu c√≥)
- "USER": T√™n ng∆∞·ªùi ƒë√°nh gi√° (n·∫øu c√≥)

H√£y s·ª≠ d·ª•ng T·∫§T C·∫¢ th√¥ng tin c√≥ s·∫µn ƒë·ªÉ ph√¢n t√≠ch SWOT m·ªôt c√°ch to√†n di·ªán.

# LOGIC PH√ÇN T√çCH & X·ª¨ L√ù (ENTERPRISE-LEVEL)
H√£y th·ª±c hi·ªán quy tr√¨nh suy lu·∫≠n hi·ªáu qu·∫£ v√† ch√≠nh x√°c:

1. **Ph√¢n t√≠ch C·∫£m x√∫c & Kh√≠a c·∫°nh (Sentiment + Aspect):** 
   - X√°c ƒë·ªãnh c·∫£m x√∫c (T√≠ch c·ª±c/Ti√™u c·ª±c) V√Ä kh√≠a c·∫°nh (Gi√° c·∫£, Ch·∫•t l∆∞·ª£ng, D·ªãch v·ª•, Kh√¥ng gian, Menu...) trong m·ªôt b∆∞·ªõc.
   - S·ª≠ d·ª•ng th√¥ng tin b·ªï sung (PRICE, RATING, MENU) ƒë·ªÉ ph√¢n t√≠ch s√¢u h∆°n.

2. **Gom nh√≥m th√¥ng minh (Smart Clustering):**
   - Gom c√°c ƒë√°nh gi√° c√≥ c√πng kh√≠a c·∫°nh V√Ä c·∫£m x√∫c l·∫°i.
   - T·∫°o m√¥ t·∫£ t·ªïng h·ª£p ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß (1-2 c√¢u).
   - ∆Øu ti√™n c√°c v·∫•n ƒë·ªÅ xu·∫•t hi·ªán nhi·ªÅu l·∫ßn.

3. **Mapping SWOT (Quy t·∫Øc x·∫øp lo·∫°i):**
   
   **Khi ph√¢n t√≠ch ƒë√°nh gi√° v·ªÅ MY_SHOP (qu√°n c·ªßa t√¥i):**
   - MY_SHOP + T√≠ch c·ª±c -> STRENGTHS (ƒêi·ªÉm m·∫°nh c·ªßa t√¥i).
   - MY_SHOP + Ti√™u c·ª±c -> WEAKNESSES (ƒêi·ªÉm y·∫øu c·ªßa t√¥i).
   - T·ª´ ƒë√°nh gi√° v·ªÅ MY_SHOP, c≈©ng c√≥ th·ªÉ suy ra:
     * OPPORTUNITIES: C∆° h·ªôi c·∫£i thi·ªán d·ª±a tr√™n ƒëi·ªÉm y·∫øu c·ªßa t√¥i ho·∫∑c th·ªã tr∆∞·ªùng.
     * THREATS: Th√°ch th·ª©c ti·ªÅm ·∫©n t·ª´ th·ªã tr∆∞·ªùng ho·∫∑c xu h∆∞·ªõng.
   
   **Khi ph√¢n t√≠ch ƒë√°nh gi√° v·ªÅ COMPETITOR (ƒë·ªëi th·ªß):**
   - COMPETITOR + T√≠ch c·ª±c -> THREATS (Th√°ch th·ª©c - ƒë·ªëi th·ªß l√†m t·ªët h∆°n).
   - COMPETITOR + Ti√™u c·ª±c -> OPPORTUNITIES (C∆° h·ªôi - khai th√°c ƒëi·ªÉm y·∫øu ƒë·ªëi th·ªß).

4. **PH√ÇN T√çCH CHI·∫æN L∆Ø·ª¢C DOANH NGHI·ªÜP (QUAN TR·ªåNG):**
   - ƒê√°nh gi√° M·ª®C ƒê·ªò ·∫¢NH H∆Ø·ªûNG (Impact): High/Medium/Low
   - ƒê√°nh gi√° M·ª®C ƒê·ªò KH·∫¢ THI ƒë·ªÉ c·∫£i thi·ªán (Feasibility): High/Medium/Low
   - ƒê√°nh gi√° M·ª®C ƒê·ªò KH·∫®N C·∫§P (Urgency): High/Medium/Low
   - ƒê·ªÅ xu·∫•t H√ÄNH ƒê·ªòNG C·ª§ TH·ªÇ cho m·ªói item
   - X√°c ƒë·ªãnh KPIs ƒë·ªÉ ƒëo l∆∞·ªùng k·∫øt qu·∫£"""

    enterprise_output = """
# OUTPUT FORMAT (ƒê·ªäNH D·∫†NG ƒê·∫¶U RA - ENTERPRISE LEVEL)
Tr·∫£ v·ªÅ k·∫øt qu·∫£ duy nh·∫•t d∆∞·ªõi d·∫°ng **JSON Object** (kh√¥ng k√®m l·ªùi d·∫´n), v·ªõi c·∫•u tr√∫c sau:

{
  "SWOT_Analysis": {
    "Strengths": [
      {
        "topic": "T√™n ch·ªß ƒë·ªÅ ng·∫Øn g·ªçn",
        "description": "M√¥ t·∫£ chi ti·∫øt v√† s√¢u s·∫Øc v·ªÅ ƒëi·ªÉm m·∫°nh n√†y",
        "impact": "High/Medium/Low",
        "priority_score": 8.5,
        "kpi_metrics": ["KPI c·ª• th·ªÉ 1", "KPI c·ª• th·ªÉ 2"],
        "leverage_strategy": "C√°ch t·∫≠n d·ª•ng ƒëi·ªÉm m·∫°nh n√†y ƒë·ªÉ tƒÉng tr∆∞·ªüng"
      }
    ],
    "Weaknesses": [
      {
        "topic": "T√™n ch·ªß ƒë·ªÅ ng·∫Øn g·ªçn",
        "description": "M√¥ t·∫£ chi ti·∫øt v·∫•n ƒë·ªÅ ƒëang g·∫∑p ph·∫£i",
        "impact": "High/Medium/Low",
        "root_cause": "Nguy√™n nh√¢n g·ªëc r·ªÖ c·ªßa v·∫•n ƒë·ªÅ",
        "priority_score": 7.0,
        "improvement_cost": "High/Medium/Low",
        "mitigation_plan": "K·∫ø ho·∫°ch kh·∫Øc ph·ª•c ng·∫Øn g·ªçn v·ªõi b∆∞·ªõc c·ª• th·ªÉ"
      }
    ],
    "Opportunities": [
      {
        "topic": "T√™n c∆° h·ªôi ng·∫Øn g·ªçn",
        "description": "M√¥ t·∫£ c∆° h·ªôi t·ª´ th·ªã tr∆∞·ªùng ho·∫∑c ƒëi·ªÉm y·∫øu ƒë·ªëi th·ªß",
        "action_idea": "G·ª£i √Ω h√†nh ƒë·ªông c·ª• th·ªÉ",
        "priority_score": 9.0,
        "market_size": "Large/Medium/Small",
        "time_to_capture": "Short term/Medium term/Long term",
        "required_investment": "High/Medium/Low"
      }
    ],
    "Threats": [
      {
        "topic": "T√™n th√°ch th·ª©c ng·∫Øn g·ªçn",
        "description": "M√¥ t·∫£ r·ªßi ro t·ª´ ƒë·ªëi th·ªß ho·∫∑c th·ªã tr∆∞·ªùng",
        "risk_level": "High/Medium/Low",
        "probability": "High/Medium/Low",
        "severity": "High/Medium/Low",
        "contingency_plan": "K·∫ø ho·∫°ch ·ª©ng ph√≥ n·∫øu r·ªßi ro x·∫£y ra"
      }
    ]
  },
  "Key_Insights": [
    "Insight quan tr·ªçng 1 t·ª´ ph√¢n t√≠ch",
    "Insight quan tr·ªçng 2 t·ª´ ph√¢n t√≠ch",
    "Insight quan tr·ªçng 3 t·ª´ ph√¢n t√≠ch"
  ],
  "Competitive_Analysis": {
      "my_scores": {
          "quality": 8, "price": 7, "service": 6, "location": 9, "brand": 7, "innovation": 5
      },
      "competitor_scores": {
          "quality": 7, "price": 6, "service": 8, "location": 8, "brand": 9, "innovation": 6
      },
      "justification": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao ch·∫•m ƒëi·ªÉm nh∆∞ v·∫≠y (v√≠ d·ª•: ƒê·ªëi th·ªß c√≥ th∆∞∆°ng hi·ªáu m·∫°nh nh∆∞ng gi√° cao...)"
  },
  "Executive_Summary": "M·ªôt ƒëo·∫°n vƒÉn ng·∫Øn kho·∫£ng 100 t·ª´ t·ªïng k·∫øt t√¨nh h√¨nh chung, bao g·ªìm: t√¨nh tr·∫°ng hi·ªán t·∫°i, ƒëi·ªÉm n·ªïi b·∫≠t nh·∫•t, v√† khuy·∫øn ngh·ªã ∆∞u ti√™n h√†ng ƒë·∫ßu."
}

QUAN TR·ªåNG: 
1. Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch n√†o kh√°c.
2. priority_score l√† s·ªë t·ª´ 1-10, c√†ng cao c√†ng quan tr·ªçng.
3. M·ªói category ph·∫£i c√≥ √≠t nh·∫•t 1 item n·∫øu c√≥ d·ªØ li·ªáu li√™n quan.
4. ƒê·∫£m b·∫£o m·ªói item c√≥ ƒë·∫ßy ƒë·ªß c√°c tr∆∞·ªùng nh∆∞ ƒë·ªãnh d·∫°ng tr√™n."""

    return base_prompt + enterprise_output




def format_reviews_for_prompt(reviews_data: List[Dict[str, Any]], compact: bool = True) -> str:
    """
    Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu reviews th√†nh ƒë·ªãnh d·∫°ng vƒÉn b·∫£n ƒë·ªÉ g·ª≠i cho AI
    T·ªëi ∆∞u h√≥a format ƒë·ªÉ gi·∫£m token v√† tƒÉng hi·ªáu qu·∫£
    
    Args:
        reviews_data: List c√°c dict v·ªõi keys: 'review', 'source', v√† c√°c keys kh√°c
        compact: N·∫øu True, s·ª≠ d·ª•ng format compact ƒë·ªÉ ti·∫øt ki·ªám token
    
    Returns:
        Chu·ªói vƒÉn b·∫£n ƒë√£ format
    """
    if compact:
        formatted_text = "\n# REVIEWS DATA (Format: SOURCE|CONTENT|PRICE|RATING|MENU|DATE)\n\n"
        
        for review in reviews_data:
            review_text = review.get('review', '').strip()
            if not review_text:
                continue
            
            source = review.get('source', 'UNKNOWN')
            parts = [source, review_text]
            
            # Th√™m c√°c th√¥ng tin b·ªï sung n·∫øu c√≥ (ch·ªâ gi√° tr·ªã kh√¥ng r·ªóng)
            for key in ['price', 'rating', 'menu', 'date']:
                if key in review and pd.notna(review.get(key)):
                    val = str(review.get(key)).strip()
                    if val and val.lower() != 'nan':
                        parts.append(val)
                    else:
                        parts.append('')
                else:
                    parts.append('')
            
            # Format: SOURCE|CONTENT|PRICE|RATING|MENU|DATE
            formatted_text += "|".join(parts) + "\n"
    else:
        # Format chi ti·∫øt (d√πng khi c·∫ßn)
        formatted_text = "\n# DANH S√ÅCH ƒê√ÅNH GI√Å V√Ä TH√îNG TIN CHI TI·∫æT\n\n"
        
        for idx, review in enumerate(reviews_data, 1):
            source = review.get('source', 'UNKNOWN')
            review_text = review.get('review', '').strip()
            
            if review_text:
                formatted_text += f"#{idx} [{source}]: {review_text}"
                
                # Th√™m th√¥ng tin b·ªï sung ng·∫Øn g·ªçn
                extras = []
                for key, label in [('price', 'Gi√°'), ('rating', 'ƒêi·ªÉm'), ('menu', 'M√≥n'), ('date', 'Ng√†y')]:
                    if key in review and pd.notna(review.get(key)):
                        val = str(review.get(key)).strip()
                        if val and val.lower() != 'nan':
                            extras.append(f"{label}:{val}")
                
                if extras:
                    formatted_text += f" ({', '.join(extras)})"
                formatted_text += "\n"
    
    return formatted_text


def analyze_swot_with_gemini(reviews_data: List[Dict[str, Any]], batch_size: int = 500, 
                             analysis_type: str = 'FULL') -> Dict[str, Any]:
    """
    G·ª≠i d·ªØ li·ªáu reviews ƒë·∫øn Gemini API v√† nh·∫≠n k·∫øt qu·∫£ ph√¢n t√≠ch SWOT
    H·ªó tr·ª£ x·ª≠ l√Ω batch cho d·ªØ li·ªáu l·ªõn
    
    Args:
        reviews_data: List c√°c dict v·ªõi keys: 'review', 'source'
        batch_size: S·ªë l∆∞·ª£ng reviews t·ªëi ƒëa m·ªói batch (m·∫∑c ƒë·ªãnh 500)
        analysis_type: 'FULL' (ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß), 'MY_SHOP_ONLY' (ch·ªâ Strengths/Weaknesses), 
                       'COMPETITOR_ONLY' (ch·ªâ Opportunities/Threats)
    
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ SWOT analysis
    """
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m v√†o file .env ho·∫∑c Streamlit Secrets")
    
    # Kh·ªüi t·∫°o model Gemini 2.5 Flash
    # Th·ª≠ c√°c model name theo th·ª© t·ª± ∆∞u ti√™n
    model_names = ['gemini-2.5-flash', 'gemini-2.0-flash-exp', 'gemini-1.5-flash']
    model = None
    
    for model_name in model_names:
        try:
            model = genai.GenerativeModel(model_name)
            break
        except Exception as e:
            continue
    
    if model is None:
        # Fallback cu·ªëi c√πng
        model = genai.GenerativeModel('gemini-1.5-flash')
    
    # X·ª≠ l√Ω batch n·∫øu d·ªØ li·ªáu qu√° l·ªõn
    total_reviews = len(reviews_data)
    
    if total_reviews <= batch_size:
        # X·ª≠ l√Ω m·ªôt l·∫ßn n·∫øu d·ªØ li·ªáu nh·ªè
        import streamlit as st
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("üîÑ ƒêang g·ª≠i d·ªØ li·ªáu ƒë·∫øn AI...")
            progress_bar.progress(0.3)
            
            result = _analyze_single_batch(model, reviews_data, analysis_type)
            
            progress_bar.progress(1.0)
            status_text.text("‚úÖ Ho√†n th√†nh ph√¢n t√≠ch!")
            time.sleep(0.5)  # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng m·ªôt ch√∫t
            progress_bar.empty()
            status_text.empty()
            
            return result
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            raise
    else:
        # X·ª≠ l√Ω nhi·ªÅu batch v√† t·ªïng h·ª£p k·∫øt qu·∫£ (T·ªêI ∆ØU H√ìA)
        import streamlit as st
        
        st.info(f"üìä D·ªØ li·ªáu l·ªõn ({total_reviews:,} reviews). ƒêang ph√¢n t√≠ch theo batch t·ªëi ∆∞u...")
        
        all_results = {
            "SWOT_Analysis": {
                "Strengths": [],
                "Weaknesses": [],
                "Opportunities": [],
                "Threats": []
            },
            "Executive_Summary": ""
        }
        
        # T√°ch MY_SHOP v√† COMPETITOR ƒë·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£ h∆°n
        my_shop_data = [r for r in reviews_data if r.get('source') == 'MY_SHOP']
        competitor_data = [r for r in reviews_data if r.get('source') == 'COMPETITOR']
        
        all_summaries = []
        
        # X·ª≠ l√Ω MY_SHOP (ch·ªâ t·∫°o Strengths v√† Weaknesses)
        if my_shop_data:
            num_batches_my_shop = (len(my_shop_data) + batch_size - 1) // batch_size
            for i in range(0, len(my_shop_data), batch_size):
                batch = my_shop_data[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                
                # Progress indicator chi ti·∫øt
                progress_value = (batch_num - 1) / num_batches_my_shop
                progress_text = f"üîÑ MY_SHOP batch {batch_num}/{num_batches_my_shop} ({len(batch)} reviews)..."
                
                with st.spinner(progress_text):
                    try:
                        batch_result = _analyze_single_batch(model, batch, 'MY_SHOP_ONLY' if analysis_type == 'MY_SHOP_ONLY' else 'FULL')
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω MY_SHOP batch {batch_num}: {str(e)}")
                        # Ti·∫øp t·ª•c v·ªõi batch ti·∫øp theo thay v√¨ d·ª´ng ho√†n to√†n
                        continue
                    
                    all_results["SWOT_Analysis"]["Strengths"].extend(
                        batch_result.get("SWOT_Analysis", {}).get("Strengths", [])
                    )
                    all_results["SWOT_Analysis"]["Weaknesses"].extend(
                        batch_result.get("SWOT_Analysis", {}).get("Weaknesses", [])
                    )
                    all_summaries.append(batch_result.get("Executive_Summary", ""))
        
        # X·ª≠ l√Ω COMPETITOR (ch·ªâ t·∫°o Opportunities v√† Threats)
        if competitor_data:
            num_batches_competitor = (len(competitor_data) + batch_size - 1) // batch_size
            for i in range(0, len(competitor_data), batch_size):
                batch = competitor_data[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                
                # Progress indicator chi ti·∫øt
                progress_text = f"üîÑ COMPETITOR batch {batch_num}/{num_batches_competitor} ({len(batch)} reviews)..."
                
                with st.spinner(progress_text):
                    try:
                        batch_result = _analyze_single_batch(model, batch, 'COMPETITOR_ONLY' if analysis_type == 'COMPETITOR_ONLY' else 'FULL')
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω COMPETITOR batch {batch_num}: {str(e)}")
                        # Ti·∫øp t·ª•c v·ªõi batch ti·∫øp theo thay v√¨ d·ª´ng ho√†n to√†n
                        continue
                    
                    all_results["SWOT_Analysis"]["Opportunities"].extend(
                        batch_result.get("SWOT_Analysis", {}).get("Opportunities", [])
                    )
                    all_results["SWOT_Analysis"]["Threats"].extend(
                        batch_result.get("SWOT_Analysis", {}).get("Threats", [])
                    )
                    all_summaries.append(batch_result.get("Executive_Summary", ""))
        
        # T·ªïng h·ª£p Executive Summary (t·ªëi ∆∞u - ch·ªâ l·∫•y 5 summary ƒë·∫ßu)
        if all_summaries:
            if len(all_summaries) > 1:
                # T·ªïng h·ª£p b·∫±ng c√°ch l·∫•y summary ƒë·∫ßu ti√™n v√† th√™m th√¥ng tin t·ª´ c√°c summary kh√°c
                main_summary = all_summaries[0]
                if len(all_summaries) > 1:
                    additional_info = " | ".join(all_summaries[1:5])  # L·∫•y t·ªëi ƒëa 4 summary c√≤n l·∫°i
                    all_results["Executive_Summary"] = f"{main_summary} {additional_info}"[:500]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
                else:
                    all_results["Executive_Summary"] = main_summary
            else:
                all_results["Executive_Summary"] = all_summaries[0]
        
        # Lo·∫°i b·ªè duplicate v√† merge items t∆∞∆°ng t·ª± (t·ªëi ∆∞u)
        for category in ["Strengths", "Weaknesses", "Opportunities", "Threats"]:
            seen_topics = {}
            for item in all_results["SWOT_Analysis"][category]:
                topic = item.get("topic", "").lower().strip()
                if topic:
                    if topic not in seen_topics:
                        seen_topics[topic] = item
                    else:
                        # Merge n·∫øu tr√πng - ∆∞u ti√™n impact cao h∆°n
                        existing = seen_topics[topic]
                        existing_impact = existing.get("impact", "Low") or existing.get("risk_level", "Low")
                        new_impact = item.get("impact", "Low") or item.get("risk_level", "Low")
                        impact_order = {"High": 3, "Medium": 2, "Low": 1}
                        if impact_order.get(new_impact, 1) > impact_order.get(existing_impact, 1):
                            seen_topics[topic] = item
            
            all_results["SWOT_Analysis"][category] = list(seen_topics.values())
        
        return all_results


def _analyze_single_batch(model, reviews_data: List[Dict[str, Any]], analysis_type: str = 'FULL') -> Dict[str, Any]:
    """
    Ph√¢n t√≠ch m·ªôt batch reviews v·ªõi t·ªëi ∆∞u h√≥a
    
    Args:
        model: Gemini model instance
        reviews_data: List c√°c dict v·ªõi keys: 'review', 'source', v√† c√°c keys kh√°c
        analysis_type: 'FULL' (ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß), 'MY_SHOP_ONLY' (ch·ªâ Strengths/Weaknesses), 
                       'COMPETITOR_ONLY' (ch·ªâ Opportunities/Threats)
    
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ SWOT analysis
    """
    # X√¢y d·ª±ng prompt ƒë·∫ßy ƒë·ªß
    system_prompt = build_system_prompt()
    
    # S·ª≠ d·ª•ng format compact ƒë·ªÉ ti·∫øt ki·ªám token
    reviews_text = format_reviews_for_prompt(reviews_data, compact=True)
    
    # Th·ªëng k√™ nhanh ƒë·ªÉ AI hi·ªÉu context
    my_shop_count = sum(1 for r in reviews_data if r.get('source') == 'MY_SHOP')
    competitor_count = sum(1 for r in reviews_data if r.get('source') == 'COMPETITOR')
    
    # T·∫°o summary ng·∫Øn g·ªçn
    summary = f"\n# TH·ªêNG K√ä NHANH\n"
    summary += f"- T·ªïng s·ªë reviews: {len(reviews_data)}\n"
    summary += f"- MY_SHOP: {my_shop_count} reviews\n"
    summary += f"- COMPETITOR: {competitor_count} reviews\n"
    
    # H∆∞·ªõng d·∫´n ph√¢n t√≠ch theo context
    if my_shop_count > 0 and competitor_count == 0:
        # Ch·ªâ c√≥ MY_SHOP reviews - ph√¢n t√≠ch SWOT c·ªßa m√¨nh
        summary += f"\n**CONTEXT QUAN TR·ªåNG:** ƒê√¢y l√† ƒë√°nh gi√° v·ªÅ QU√ÅN C·ª¶A T√îI. H√£y ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß SWOT c·ªßa m√¨nh:\n"
        summary += f"- **Strengths:** T·ª´ ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ qu√°n c·ªßa t√¥i\n"
        summary += f"- **Weaknesses:** T·ª´ ƒë√°nh gi√° ti√™u c·ª±c v·ªÅ qu√°n c·ªßa t√¥i\n"
        summary += f"- **Opportunities:** C∆° h·ªôi c·∫£i thi·ªán, m·ªü r·ªông, ho·∫∑c th·ªã tr∆∞·ªùng d·ª±a tr√™n insights t·ª´ d·ªØ li·ªáu (v√≠ d·ª•: n·∫øu c√≥ nhi·ªÅu ph√†n n√†n v·ªÅ gi√°, ƒë√≥ l√† c∆° h·ªôi t·ªëi ∆∞u gi√°)\n"
        summary += f"- **Threats:** Th√°ch th·ª©c ti·ªÅm ·∫©n, xu h∆∞·ªõng, ho·∫∑c r·ªßi ro t·ª´ th·ªã tr∆∞·ªùng (v√≠ d·ª•: n·∫øu kh√°ch h√†ng y√™u c·∫ßu t√≠nh nƒÉng m·ªõi, ƒë√≥ l√† threat n·∫øu kh√¥ng ƒë√°p ·ª©ng)\n"
        summary += f"**L∆ØU √ù:** Ph·∫£i c√≥ √≠t nh·∫•t m·ªôt s·ªë items trong m·ªói ph·∫ßn SWOT, kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng ho√†n to√†n.\n"
    elif competitor_count > 0 and my_shop_count == 0:
        # Ch·ªâ c√≥ COMPETITOR reviews - ph√¢n t√≠ch SWOT c·ªßa ƒë·ªëi th·ªß
        summary += f"\n**CONTEXT QUAN TR·ªåNG:** ƒê√¢y l√† ƒë√°nh gi√° v·ªÅ ƒê·ªêI TH·ª¶ C·∫†NH TRANH. H√£y ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß SWOT c·ªßa ƒë·ªëi th·ªß:\n"
        summary += f"- **Strengths:** ƒêi·ªÉm m·∫°nh c·ªßa ƒë·ªëi th·ªß (t·ª´ ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ ƒë·ªëi th·ªß)\n"
        summary += f"- **Weaknesses:** ƒêi·ªÉm y·∫øu c·ªßa ƒë·ªëi th·ªß (t·ª´ ƒë√°nh gi√° ti√™u c·ª±c v·ªÅ ƒë·ªëi th·ªß)\n"
        summary += f"- **Opportunities:** C∆° h·ªôi cho t√¥i (khai th√°c ƒëi·ªÉm y·∫øu ƒë·ªëi th·ªß, th·ªã tr∆∞·ªùng)\n"
        summary += f"- **Threats:** Th√°ch th·ª©c cho t√¥i (ƒë·ªëi th·ªß l√†m t·ªët, c·∫°nh tranh)\n"
        summary += f"**L∆ØU √ù:** Ph·∫£i c√≥ √≠t nh·∫•t m·ªôt s·ªë items trong m·ªói ph·∫ßn SWOT, kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng ho√†n to√†n.\n"
    else:
        # C√≥ c·∫£ 2 lo·∫°i - ph√¢n t√≠ch t·ªïng h·ª£p
        summary += f"\n**CONTEXT:** C√≥ c·∫£ ƒë√°nh gi√° v·ªÅ qu√°n c·ªßa t√¥i v√† ƒë·ªëi th·ªß. Ph√¢n t√≠ch SWOT t·ªïng h·ª£p:\n"
        summary += f"- **Strengths:** T·ª´ ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ qu√°n c·ªßa t√¥i\n"
        summary += f"- **Weaknesses:** T·ª´ ƒë√°nh gi√° ti√™u c·ª±c v·ªÅ qu√°n c·ªßa t√¥i\n"
        summary += f"- **Opportunities:** T·ª´ ƒë√°nh gi√° ti√™u c·ª±c v·ªÅ ƒë·ªëi th·ªß + c∆° h·ªôi th·ªã tr∆∞·ªùng\n"
        summary += f"- **Threats:** T·ª´ ƒë√°nh gi√° t√≠ch c·ª±c v·ªÅ ƒë·ªëi th·ªß + th√°ch th·ª©c c·∫°nh tranh\n"
    
    # Ki·ªÉm tra c√≥ th√¥ng tin b·ªï sung kh√¥ng
    has_price = any('price' in r and pd.notna(r.get('price')) for r in reviews_data)
    has_rating = any('rating' in r and pd.notna(r.get('rating')) for r in reviews_data)
    has_menu = any('menu' in r and pd.notna(r.get('menu')) for r in reviews_data)
    
    if has_price or has_rating or has_menu:
        summary += f"- Th√¥ng tin b·ªï sung: "
        extras = []
        if has_price:
            extras.append("Gi√° c·∫£")
        if has_rating:
            extras.append("ƒêi·ªÉm ƒë√°nh gi√°")
        if has_menu:
            extras.append("Menu/S·∫£n ph·∫©m")
        summary += ", ".join(extras) + "\n"
    
    full_prompt = f"""{system_prompt}

{summary}

{reviews_text}

**Y√äU C·∫¶U:**
1. Ph√¢n t√≠ch nhanh v√† ch√≠nh x√°c
2. Gom nh√≥m c√°c ƒë√°nh gi√° t∆∞∆°ng t·ª±
3. Tr·∫£ v·ªÅ JSON ƒë√∫ng ƒë·ªãnh d·∫°ng
4. Kh√¥ng l·∫∑p l·∫°i th√¥ng tin
5. ∆Øu ti√™n c√°c insights quan tr·ªçng nh·∫•t
6. Tu√¢n th·ªß h∆∞·ªõng d·∫´n ph√¢n t√≠ch theo lo·∫°i ·ªü tr√™n"""
    
    try:
        # G·ªçi API Gemini v·ªõi timeout v√† retry
        import time
        max_retries = 3
        timeout_seconds = 120  # 2 ph√∫t timeout
        
        response = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # G·ªçi API v·ªõi timeout (s·ª≠ d·ª•ng generation_config)
                # TƒÉng max_output_tokens ƒë·ªÉ tr√°nh JSON b·ªã c·∫Øt c·ª•t
                generation_config = {
                    'max_output_tokens': 16384,  # TƒÉng t·ª´ 8192 l√™n 16384 ƒë·ªÉ ƒë·ªß cho response d√†i
                    'temperature': 0.7,
                }
                
                # Th·ª≠ g·ªçi API
                start_time = time.time()
                response = model.generate_content(
                    full_prompt,
                    generation_config=generation_config
                )
                elapsed_time = time.time() - start_time
                
                # Ki·ªÉm tra timeout
                if elapsed_time > timeout_seconds:
                    raise TimeoutError(f"API call m·∫•t h∆°n {timeout_seconds} gi√¢y")
                
                break  # Th√†nh c√¥ng, tho√°t kh·ªèi retry loop
                
            except Exception as e:
                last_error = e
                if attempt < max_retries - 1:
                    # Exponential backoff: 2^attempt seconds
                    wait_time = 2 ** attempt
                    time.sleep(wait_time)
                    continue
                else:
                    raise
        
        if response is None:
            raise Exception(f"Kh√¥ng th·ªÉ nh·∫≠n ph·∫£n h·ªìi t·ª´ API sau {max_retries} l·∫ßn th·ª≠. L·ªói cu·ªëi: {last_error}")
        
        # L·∫•y text response
        response_text = response.text.strip()
        
        # Lo·∫°i b·ªè markdown code blocks n·∫øu c√≥
        if response_text.startswith("```json"):
            response_text = response_text[7:]  # B·ªè "```json"
        if response_text.startswith("```"):
            response_text = response_text[3:]  # B·ªè "```"
        if response_text.endswith("```"):
            response_text = response_text[:-3]  # B·ªè "```" ·ªü cu·ªëi
        
        response_text = response_text.strip()
        
        # QUAN TR·ªåNG: X·ª≠ l√Ω escape sequences trong JSON string
        # Response c√≥ th·ªÉ ch·ª©a \n literal (2 k√Ω t·ª±: backslash + n) thay v√¨ newline th·ª±c s·ª±
        import re
        import codecs
        
        # Ki·ªÉm tra xem c√≥ ch·ª©a escape sequences literal kh√¥ng
        if '\\n' in response_text or '\\t' in response_text or '\\r' in response_text:
            # Decode escape sequences: chuy·ªÉn \n literal th√†nh newline th·ª±c s·ª±
            # Nh∆∞ng ph·∫£i c·∫©n th·∫≠n: ch·ªâ decode trong JSON structure, kh√¥ng decode trong string values
            # C√°ch ƒë∆°n gi·∫£n nh·∫•t: decode to√†n b·ªô, v√¨ JSON cho ph√©p newline trong string values
            try:
                # Th·ª≠ decode escape sequences
                response_text = codecs.decode(response_text, 'unicode_escape')
            except Exception:
                # N·∫øu decode kh√¥ng ƒë∆∞·ª£c (c√≥ th·ªÉ do c√≥ escape sequences kh√¥ng h·ª£p l·ªá), th·ª≠ thay th·∫ø th·ªß c√¥ng
                # Ch·ªâ thay th·∫ø c√°c escape sequences h·ª£p l·ªá trong JSON
                response_text = response_text.replace('\\n', '\n').replace('\\t', '\t').replace('\\r', '\r')
                # Kh√¥ng thay th·∫ø \\" v√† \\\\ v√¨ c√≥ th·ªÉ l√† escape trong string values
        
        # L√†m s·∫°ch JSON: lo·∫°i b·ªè k√Ω t·ª± control character kh√¥ng h·ª£p l·ªá (nh∆∞ng gi·ªØ \n, \r, \t h·ª£p l·ªá)
        # Ch·ªâ lo·∫°i b·ªè c√°c k√Ω t·ª± control kh√¥ng h·ª£p l·ªá trong JSON
        response_text = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f-\x9f]', ' ', response_text)
        
        # Th·ª≠ parse JSON
        try:
            result = json.loads(response_text)
        except json.JSONDecodeError as json_error:
            # N·∫øu l·ªói, th·ª≠ s·ª≠a m·ªôt s·ªë v·∫•n ƒë·ªÅ ph·ªï bi·∫øn
            # T√¨m JSON object trong response (c√≥ th·ªÉ c√≥ text th√™m)
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                response_text = json_match.group(0)
                # Th·ª≠ l·∫°i v·ªõi JSON ƒë√£ extract
                try:
                    result = json.loads(response_text)
                except json.JSONDecodeError as e2:
                    # N·∫øu v·∫´n l·ªói, th·ª≠ fix c√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn
                    # Fix 1: Lo·∫°i b·ªè trailing comma
                    response_text = re.sub(r',(\s*[}\]])', r'\1', response_text)
                    
                    # Fix 2: X·ª≠ l√Ω JSON b·ªã c·∫Øt c·ª•t - ƒë√≥ng c√°c brackets/braces ch∆∞a ƒë√≥ng
                    error_pos = getattr(e2, 'pos', None)
                    error_line = getattr(e2, 'lineno', None)
                    error_col = getattr(e2, 'colno', None)
                    
                    # ƒê·∫øm s·ªë l∆∞·ª£ng {, }, [, ] ƒë·ªÉ xem c√≥ thi·∫øu kh√¥ng
                    open_braces = response_text.count('{')
                    close_braces = response_text.count('}')
                    open_brackets = response_text.count('[')
                    close_brackets = response_text.count(']')
                    
                    # N·∫øu JSON b·ªã c·∫Øt c·ª•t (thi·∫øu closing brackets/braces), th·ª≠ ƒë√≥ng ch√∫ng
                    if open_braces > close_braces or open_brackets > close_brackets:
                        fixed_text = response_text
                        
                        # T√¨m v·ªã tr√≠ cu·ªëi c√πng c√≥ th·ªÉ ch√®n closing brackets
                        # T√¨m v·ªã tr√≠ sau d·∫•u ph·∫©y ho·∫∑c sau gi√° tr·ªã cu·ªëi c√πng
                        last_comma_pos = response_text.rfind(',')
                        if last_comma_pos > 0:
                            # Lo·∫°i b·ªè d·∫•u ph·∫©y cu·ªëi v√† ƒë√≥ng c√°c c·∫•u tr√∫c
                            fixed_text = response_text[:last_comma_pos]
                        
                        # ƒê√≥ng arrays tr∆∞·ªõc
                        for _ in range(open_brackets - close_brackets):
                            fixed_text += ']'
                        
                        # ƒê√≥ng objects sau
                        for _ in range(open_braces - close_braces):
                            fixed_text += '}'
                        
                        # Th·ª≠ parse v·ªõi text ƒë√£ fix
                        try:
                            result = json.loads(fixed_text)
                        except:
                            # N·∫øu v·∫´n kh√¥ng ƒë∆∞·ª£c, ti·∫øp t·ª•c v·ªõi c√°c fix kh√°c
                            pass
                    
                    # Fix 3: T√¨m JSON h·ª£p l·ªá b·∫±ng c√°ch ƒë·∫øm braces t·ª´ ƒë·∫ßu (x·ª≠ l√Ω string trong JSON)
                    brace_count = 0
                    bracket_count = 0
                    last_valid_pos = len(response_text)
                    in_string = False
                    escape_next = False
                    
                    for i, char in enumerate(response_text):
                        if escape_next:
                            escape_next = False
                            continue
                        
                        if char == '\\':
                            escape_next = True
                            continue
                        
                        if char == '"' and not escape_next:
                            in_string = not in_string
                            continue
                        
                        if not in_string:
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0 and bracket_count == 0:
                                    last_valid_pos = i + 1
                                    break
                            elif char == '[':
                                bracket_count += 1
                            elif char == ']':
                                bracket_count -= 1
                    
                    # Th·ª≠ parse v·ªõi JSON ƒë√£ extract v√† ƒë√≥ng c√°c c·∫•u tr√∫c c√≤n thi·∫øu
                    if last_valid_pos < len(response_text) or brace_count > 0 or bracket_count > 0:
                        try:
                            extract_text = response_text[:last_valid_pos] if last_valid_pos < len(response_text) else response_text
                            
                            # ƒê√≥ng arrays
                            for _ in range(bracket_count):
                                extract_text += ']'
                            
                            # ƒê√≥ng objects
                            for _ in range(brace_count):
                                extract_text += '}'
                            
                            result = json.loads(extract_text)
                        except json.JSONDecodeError as e3:
                            # N·∫øu v·∫´n l·ªói, th·ª≠ parse l·∫°i v·ªõi text g·ªëc ƒë√£ fix trailing comma
                            try:
                                result = json.loads(response_text)
                            except json.JSONDecodeError:
                                raise ValueError(
                                    f"Kh√¥ng th·ªÉ parse JSON sau nhi·ªÅu l·∫ßn th·ª≠. "
                                    f"L·ªói cu·ªëi: {e3}\n"
                                    f"V·ªã tr√≠: line {error_line or '?'}, column {error_col or '?'}\n"
                                    f"Response (500 k√Ω t·ª± ƒë·∫ßu): {response_text[:500]}\n"
                                    f"Response (500 k√Ω t·ª± cu·ªëi): ...{response_text[-500:]}"
                                )
                    else:
                        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c v·ªã tr√≠ h·ª£p l·ªá, th·ª≠ parse l·∫°i v·ªõi text g·ªëc
                        try:
                            result = json.loads(response_text)
                        except json.JSONDecodeError as e3:
                            raise ValueError(
                                f"Kh√¥ng th·ªÉ parse JSON. L·ªói: {e3}\n"
                                f"V·ªã tr√≠: line {error_line or '?'}, column {error_col or '?'}\n"
                                f"Response (500 k√Ω t·ª± ƒë·∫ßu): {response_text[:500]}"
                            )
            else:
                raise ValueError(f"Kh√¥ng t√¨m th·∫•y JSON trong response. L·ªói: {json_error}\nResponse: {response_text[:500]}")
        
        return result
        
    except json.JSONDecodeError as e:
        # L∆∞u response ƒë·ªÉ debug
        error_msg = f"L·ªói parse JSON t·ª´ AI response: {e}\n"
        error_msg += f"V·ªã tr√≠ l·ªói: line {e.lineno}, column {e.colno}\n"
        error_msg += f"Response text (500 k√Ω t·ª± ƒë·∫ßu): {response_text[:500]}\n"
        if len(response_text) > 500:
            error_msg += f"Response text (500 k√Ω t·ª± cu·ªëi): ...{response_text[-500:]}"
        raise ValueError(error_msg)
    except Exception as e:
        error_str = str(e)
        
        # X·ª≠ l√Ω c√°c l·ªói ph·ªï bi·∫øn v·ªõi th√¥ng b√°o th√¢n thi·ªán
        if "Insufficient Balance" in error_str or "402" in error_str:
            raise Exception(
                "‚ùå **L·ªói: T√†i kho·∫£n Gemini kh√¥ng ƒë·ªß s·ªë d∆∞**\n\n"
                "Vui l√≤ng:\n"
                "1. Ki·ªÉm tra s·ªë d∆∞ t√†i kho·∫£n t·∫°i: https://makersuite.google.com/app/apikey\n"
                "2. N·∫°p th√™m ti·ªÅn v√†o t√†i kho·∫£n Gemini\n"
                "3. Ho·∫∑c s·ª≠ d·ª•ng API key kh√°c c√≥ ƒë·ªß s·ªë d∆∞\n\n"
                f"Chi ti·∫øt l·ªói: {error_str}"
            )
        elif "401" in error_str or "Invalid API key" in error_str or "Unauthorized" in error_str:
            raise Exception(
                "‚ùå **L·ªói: API Key kh√¥ng h·ª£p l·ªá**\n\n"
                "Vui l√≤ng:\n"
                "1. Ki·ªÉm tra l·∫°i API key trong file .env ho·∫∑c Streamlit Secrets\n"
                "2. ƒê·∫£m b·∫£o API key ƒë√∫ng format\n"
                "3. L·∫•y API key m·ªõi t·∫°i: https://makersuite.google.com/app/apikey\n\n"
                f"Chi ti·∫øt l·ªói: {error_str}"
            )
        elif "429" in error_str or "rate limit" in error_str.lower():
            raise Exception(
                "‚ùå **L·ªói: V∆∞·ª£t qu√° gi·ªõi h·∫°n rate limit**\n\n"
                "Vui l√≤ng:\n"
                "1. ƒê·ª£i m·ªôt ch√∫t r·ªìi th·ª≠ l·∫°i\n"
                "2. Gi·∫£m s·ªë l∆∞·ª£ng reviews trong m·ªói l·∫ßn ph√¢n t√≠ch\n"
                "3. Ho·∫∑c n√¢ng c·∫•p g√≥i API c·ªßa Gemini\n\n"
                f"Chi ti·∫øt l·ªói: {error_str}"
            )
        else:
            raise Exception(f"L·ªói khi g·ªçi Gemini API: {error_str}")


def validate_swot_result(result: Dict[str, Any]) -> bool:
    """
    Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa k·∫øt qu·∫£ SWOT
    
    Args:
        result: Dict ch·ª©a k·∫øt qu·∫£ SWOT
    
    Returns:
        True n·∫øu h·ª£p l·ªá, False n·∫øu kh√¥ng
    """
    if not isinstance(result, dict):
        return False
    
    if "SWOT_Analysis" not in result:
        return False
    
    swot = result.get("SWOT_Analysis", {})
    required_keys = ["Strengths", "Weaknesses", "Opportunities", "Threats"]
    
    for key in required_keys:
        if key not in swot:
            return False
        if not isinstance(swot[key], list):
            return False
    
    return True
