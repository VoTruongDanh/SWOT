"""
Utility Functions - X·ª≠ l√Ω d·ªØ li·ªáu v√† visualization
"""
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from typing import List, Dict, Any, Tuple
import streamlit as st


def load_and_clean_data(uploaded_file, file_name: str = None) -> pd.DataFrame:
    """
    ƒê·ªçc v√† l√†m s·∫°ch d·ªØ li·ªáu t·ª´ file Excel/CSV
    T·ª± ƒë·ªông ph√°t hi·ªán c√°c c·ªôt c·∫ßn thi·∫øt th√¥ng minh
    
    Args:
        uploaded_file: File object t·ª´ Streamlit uploader
        file_name: T√™n file (optional, s·∫Ω l·∫•y t·ª´ uploaded_file.name n·∫øu kh√¥ng c√≥)
    
    Returns:
        DataFrame ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
    """
    # L·∫•y t√™n file n·∫øu ch∆∞a c√≥
    if file_name is None:
        file_name = getattr(uploaded_file, 'name', '')
    try:
        # ƒê·ªçc file d·ª±a tr√™n extension
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        # Th·ª≠ nhi·ªÅu encoding ph·ªï bi·∫øn
        if file_extension == 'csv':
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-16']
            for encoding in encodings:
                try:
                    uploaded_file.seek(0)  # Reset file pointer
                    # Use separator sniffing
                    df = pd.read_csv(uploaded_file, encoding=encoding, sep=None, engine='python')
                    
                    # If sniffing returned 1 column, try fallback separators
                    if len(df.columns) == 1:
                         # Prioritize semicolon, then tab, then comma (explicitly)
                         for sep in [';', '\t', ',']:
                             try:
                                 uploaded_file.seek(0)
                                 df_temp = pd.read_csv(uploaded_file, encoding=encoding, sep=sep, engine='python')
                                 if len(df_temp.columns) > 1:
                                     df = df_temp
                                     break
                             except:
                                 pass
                    
                    break
                except UnicodeDecodeError:
                    continue
                except Exception:
                     continue

            if df is None:
                raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc file CSV v·ªõi c√°c encoding ph·ªï bi·∫øn")
        elif file_extension in ['xlsx', 'xls']:
            df = pd.read_excel(uploaded_file)
        else:
            raise ValueError(f"ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_extension}")
        
        # L√†m s·∫°ch d·ªØ li·ªáu
        # Lo·∫°i b·ªè d√≤ng tr·ªëng
        df = df.dropna(how='all')
        
        if len(df) == 0:
            raise ValueError("File kh√¥ng ch·ª©a d·ªØ li·ªáu")
        
        # L∆∞u t√™n c·ªôt g·ªëc ƒë·ªÉ hi·ªÉn th·ªã (tr∆∞·ªõc khi normalize)
        original_columns = df.columns.tolist()
        column_mapping = {col.strip().lower(): col for col in original_columns}
        
        # Chu·∫©n h√≥a t√™n c·ªôt (chuy·ªÉn v·ªÅ lowercase, b·ªè kho·∫£ng tr·∫Øng)
        df.columns = df.columns.str.strip().str.lower()
        
        # T√¨m c·ªôt ch·ª©a review v√† source
        review_cols = []  # C√≥ th·ªÉ c√≥ nhi·ªÅu c·ªôt ch·ª©a review
        source_col = None
        
        # B∆∞·ªõc 1: T√¨m T·∫§T C·∫¢ c√°c c·ªôt c√≥ th·ªÉ ch·ª©a review b·∫±ng t·ª´ kh√≥a (m·ªü r·ªông)
        possible_review_names = [
            # Ti·∫øng Anh
            'review', 'reviews', 'comment', 'comments', 'content', 'text', 'feedback',
            'comment_text', 'review_text', 'review_content', 'comment_content',
            'description', 'desc', 'note', 'notes', 'remark', 'remarks',
            'opinion', 'opinions', 'thought', 'thoughts', 'experience', 'experiences',
            'rating_text', 'rating_comment', 'user_comment', 'customer_comment',
            'review_detail', 'comment_detail', 'detail', 'details',
            'message', 'messages', 'input', 'response', 'responses',
            # Ti·∫øng Vi·ªát
            'ƒë√°nh gi√°', 'ƒë√°nh gi√° kh√°ch h√†ng', 'nh·∫≠n x√©t', 'n·ªôi dung', 'm√¥ t·∫£',
            'b√¨nh lu·∫≠n', 'ph·∫£n h·ªìi', '√Ω ki·∫øn', 'c·∫£m nh·∫≠n', 'tr·∫£i nghi·ªám',
            'chi ti·∫øt', 'ghi ch√∫', 'l·ªùi nh·∫≠n x√©t', 'l·ªùi ƒë√°nh gi√°',
            # T·ª´ kh√≥a chung
            'text', 'txt', 'content', 'data', 'info', 'information'
        ]
        
        for col in df.columns:
            col_lower = col.lower().strip()
            # Ki·ªÉm tra ch√≠nh x√°c ho·∫∑c ch·ª©a t·ª´ kh√≥a
            if any(name in col_lower or col_lower == name for name in possible_review_names):
                review_cols.append(col)
        
        # B∆∞·ªõc 2: N·∫øu kh√¥ng t√¨m th·∫•y b·∫±ng t·ª´ kh√≥a, ph√¢n t√≠ch t·∫•t c·∫£ c·ªôt text
        if not review_cols:
            text_columns = []
            text_scores = {}
            
            for col in df.columns:
                if df[col].dtype == 'object':  # Ch·ªâ x√©t c·ªôt text
                    # T√≠nh ƒëi·ªÉm d·ª±a tr√™n nhi·ªÅu y·∫øu t·ªë
                    col_lower = col.lower()
                    score = 0
                    
                    # ƒê·ªô d√†i trung b√¨nh c·ªßa text
                    avg_length = df[col].astype(str).str.len().mean()
                    if avg_length > 20:  # Text d√†i h∆°n 20 k√Ω t·ª±
                        score += avg_length / 10
                    
                    # S·ªë t·ª´ trung b√¨nh
                    word_count = df[col].astype(str).str.split().str.len().mean()
                    if word_count > 3:  # C√≥ nhi·ªÅu h∆°n 3 t·ª´
                        score += word_count * 2
                    
                    # ƒê·ªô ƒëa d·∫°ng c·ªßa n·ªôi dung (kh√¥ng ph·∫£i gi√° tr·ªã l·∫∑p l·∫°i)
                    unique_ratio = df[col].nunique() / len(df)
                    if unique_ratio > 0.5:  # H∆°n 50% gi√° tr·ªã l√† unique
                        score += unique_ratio * 100
                    
                    # Kh√¥ng ph·∫£i c·ªôt ID, code, s·ªë ho·∫∑c Item/Menu (tr·ª´ khi c√≥ ch·ªØ review)
                    excluded_review_keywords = ['id', 'code', 'number', 'num', 'no', 'stt', 'index', 'item', 'menu', 'product', 'm√≥n', 't√™n', 'category', 's·∫£n ph·∫©m']
                    has_review_keyword = any(k in col_lower for k in ['review', 'comment', 'feedback', 'ƒë√°nh gi√°', 'nh·∫≠n x√©t'])
                    
                    if any(keyword in col_lower for keyword in excluded_review_keywords) and not has_review_keyword:
                         score -= 100 # Penalize heavily
                    else:
                         score += 50
                    
                    if score > 30:  # Ng∆∞·ª°ng t·ªëi thi·ªÉu
                        text_columns.append(col)
                        text_scores[col] = score
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm v√† l·∫•y c√°c c·ªôt t·ªët nh·∫•t
            if text_columns:
                text_columns.sort(key=lambda x: text_scores[x], reverse=True)
                # L·∫•y t·ªëi ƒëa 3 c·ªôt text t·ªët nh·∫•t
                review_cols = text_columns[:3]
        
        # B∆∞·ªõc 3: X√°c ƒë·ªãnh c·ªôt review ch√≠nh
        if review_cols:
            # N·∫øu c√≥ nhi·ªÅu c·ªôt, ∆∞u ti√™n c·ªôt c√≥ t√™n r√µ r√†ng nh·∫•t
            review_col = review_cols[0]
            if len(review_cols) > 1:
                # T√¨m c·ªôt c√≥ t√™n r√µ r√†ng nh·∫•t
                for col in review_cols:
                    col_lower = col.lower()
                    if any(keyword in col_lower for keyword in ['review', 'comment', 'feedback', 'ƒë√°nh gi√°', 'nh·∫≠n x√©t']):
                        review_col = col
                        break
        else:
            review_col = None
        
        # B∆∞·ªõc 3: T√¨m c·ªôt source b·∫±ng t·ª´ kh√≥a (CH·ªà c√°c t·ª´ kh√≥a r√µ r√†ng, kh√¥ng nh·∫ßm l·∫´n)
        # Lo·∫°i tr·ª´ c√°c c·ªôt c√≥ th·ªÉ nh·∫ßm l·∫´n: "Link Source", "review_text", "address", v.v.
        excluded_keywords = ['link', 'url', 'review', 'text', 'address', 'name', 'description', 'content']
        
        possible_source_names = [
            'source', 'ngu·ªìn', 'shop_type', 'store_type', 'competitor', 'ƒë·ªëi th·ªß'
        ]
        
        for col in df.columns:
            col_lower = col.lower().strip()
            
            # B·ªè qua n·∫øu c·ªôt c√≥ t·ª´ kh√≥a b·ªã lo·∫°i tr·ª´ (tr·ª´ khi l√† "source" ch√≠nh x√°c)
            if any(excluded in col_lower for excluded in excluded_keywords) and col_lower != 'source':
                continue
            
            # Ch·ªâ ch·∫•p nh·∫≠n n·∫øu t√™n c·ªôt kh·ªõp ch√≠nh x√°c
            if col_lower == 'source' or col_lower == 'ngu·ªìn':
                source_col = col
                break
            # Ho·∫∑c c√°c t·ª´ kh√≥a r√µ r√†ng kh√°c
            elif col_lower in ['shop_type', 'store_type']:
                # Ki·ªÉm tra gi√° tr·ªã trong c·ªôt c√≥ ph·∫£i l√† MY_SHOP/COMPETITOR kh√¥ng
                sample_vals = df[col].astype(str).str.upper().str.strip().unique()[:5]
                if any(val in ['MY_SHOP', 'COMPETITOR', 'MY SHOP', 'C·ª¶A M√åNH', 'ƒê·ªêI TH·ª¶'] for val in sample_vals):
                    source_col = col
                    break
        
        # B∆∞·ªõc 4: N·∫øu kh√¥ng t√¨m th·∫•y source, th·ª≠ ph√¢n t√≠ch gi√° tr·ªã trong c√°c c·ªôt
        # QUAN TR·ªåNG: Lo·∫°i tr·ª´ c√°c c·ªôt c√≥ th·ªÉ nh·∫ßm l·∫´n (review, text, link, address, name)
        if source_col is None:
            # Lo·∫°i tr·ª´ c√°c c·ªôt kh√¥ng ph·∫£i source
            excluded_keywords_in_col = ['review', 'text', 'desc', 'content', 'comment', 
                                       'address', 'name', 'link', 'url', 'item', 'menu', 
                                       'price', 'rating', 'date', 'user', 'customer']
            
            for col in df.columns:
                col_lower = col.lower()
                
                # B·ªè qua n·∫øu c·ªôt c√≥ t·ª´ kh√≥a b·ªã lo·∫°i tr·ª´
                if any(excluded in col_lower for excluded in excluded_keywords_in_col):
                    continue
                
                # B·ªè qua c·ªôt review ƒë√£ ch·ªçn
                if col == review_col:
                    continue
                
                if df[col].dtype == 'object':
                    unique_vals = df[col].astype(str).str.upper().str.strip().unique()[:10]
                    # CH·ªà ch·∫•p nh·∫≠n n·∫øu c√≥ gi√° tr·ªã CH√çNH X√ÅC l√† MY_SHOP ho·∫∑c COMPETITOR
                    exact_source_values = ['MY_SHOP', 'COMPETITOR', 'MY SHOP', 'C·ª¶A M√åNH', 'ƒê·ªêI TH·ª¶', 'COMPETITORS']
                    matching_vals = [val for val in unique_vals if val in exact_source_values]
                    
                    # Ph·∫£i c√≥ √≠t nh·∫•t 1 gi√° tr·ªã kh·ªõp v√† kh√¥ng ph·∫£i t·∫•t c·∫£ gi√° tr·ªã ƒë·ªÅu gi·ªëng nhau (tr·ª´ khi ch·ªâ c√≥ 1 gi√° tr·ªã)
                    if matching_vals and (len(unique_vals) == 1 or len(set(unique_vals)) > 1):
                        source_col = col
                        break
        
        # B∆∞·ªõc 5: N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y review, th·ª≠ ki·ªÉm tra xem c√≥ ph·∫£i l√† file Menu/B·∫£ng gi√° kh√¥ng
        if review_col is None:
            # Check for Menu keywords
            item_keywords = ['product', 'item', 'dish', 'menu', 'm√≥n', 't√™n m√≥n', 's·∫£n ph·∫©m']
            price_keywords = ['price', 'cost', 'amount', 'gi√°', 'ƒë∆°n gi√°', 'ti·ªÅn']
            
            item_col_name = None
            found_price = False
            
            for col in df.columns:
                col_lower = col.lower()
                # Exclude ID/Code columns
                if any(x in col_lower for x in ['code', 'id', 'm√£', 'stt', 'no.', 'order']):
                    continue
                    
                if any(k in col_lower for k in item_keywords) and not item_col_name: 
                    item_col_name = col
                if any(k in col_lower for k in price_keywords): 
                    found_price = True
            
            if item_col_name and found_price:
                # ƒê√¢y l√† file Menu -> T·∫°o c·ªôt review gi·∫£ UNIQUE ƒë·ªÉ tr√°nh b·ªã drop_duplicates l·ªçc m·∫•t
                # Th√™m index ƒë·ªÉ ƒë·∫£m b·∫£o unique 100%
                df['dummy_review'] = "Menu Item: " + df[item_col_name].astype(str) + " #" + df.index.astype(str)
                review_col = 'dummy_review'
            else:
                # B√°o l·ªói nh∆∞ c≈©
                error_msg = f"Kh√¥ng t√¨m th·∫•y c·ªôt ch·ª©a n·ªôi dung ƒë√°nh gi√°.\n\n"
                error_msg += f"C√°c c·ªôt trong file: {', '.join(original_columns)}\n\n"
                error_msg += "Vui l√≤ng ƒë·∫£m b·∫£o file c√≥ c·ªôt ch·ª©a n·ªôi dung ƒë√°nh gi√° (v√≠ d·ª•: Review, ƒê√°nh gi√°, Comment, Content...)"
                raise ValueError(error_msg)
        
        # B∆∞·ªõc 6: N·∫øu kh√¥ng c√≥ source, th·ª≠ ph√°t hi·ªán th√¥ng minh
        if source_col is None:
            detected_source = None
            detection_method = None
            
            # Ph∆∞∆°ng ph√°p 1: Ph√°t hi·ªán t·ª´ t√™n file (m·ªü r·ªông t·ª´ kh√≥a)
            file_name_lower = (file_name or '').lower()
            
            # T·ª´ kh√≥a ƒë·ªëi th·ªß (m·ªü r·ªông)
            competitor_keywords = [
                'competitor', 'ƒë·ªëi th·ªß', 'rival', 'competitors',
                # Th∆∞∆°ng hi·ªáu c√† ph√™
                'starbucks', 'phuc long', 'phuclong', 'katinat', 'highlands', 'highland',
                'trung nguyen', 'trungnguyen', 'the coffee house', 'coffee house',
                'cong ca phe', 'congcaphe', 'passio', 'gong cha', 'gongcha',
                # N·ªÅn t·∫£ng
                'shopee', 'lazada', 'grab', 'now', 'baemin', 'gojek', 'go food',
                # T·ª´ kh√≥a kh√°c
                'other', 'others', 'competition', 'market'
            ]
            
            # T·ª´ kh√≥a qu√°n m√¨nh
            my_shop_keywords = [
                'my_shop', 'myshop', 'c·ªßa m√¨nh', 'cua minh', 'my store', 'mystore',
                'our shop', 'ourshop', 'our store', 'ourstore', 'my_', 'my-',
                'own', 'self', 'internal', 'n·ªôi b·ªô', 'noi bo'
            ]
            
            if any(keyword in file_name_lower for keyword in competitor_keywords):
                detected_source = 'COMPETITOR'
                detection_method = f"t√™n file '{file_name}'"
            elif any(keyword in file_name_lower for keyword in my_shop_keywords):
                detected_source = 'MY_SHOP'
                detection_method = f"t√™n file '{file_name}'"
            
            # Ph∆∞∆°ng ph√°p 2: Ph√¢n t√≠ch n·ªôi dung trong c√°c c·ªôt text (n·∫øu ch∆∞a ph√°t hi·ªán)
            if not detected_source and len(df) > 0:
                # T√¨m c√°c c·ªôt text c√≥ th·ªÉ ch·ª©a th√¥ng tin v·ªÅ brand/shop
                for col in df.columns:
                    if col != review_col and df[col].dtype == 'object':
                        # L·∫•y m·∫´u gi√° tr·ªã ƒë·ªÉ ph√¢n t√≠ch
                        sample_values = df[col].astype(str).str.lower().str.strip().dropna().unique()[:20]
                        
                        # Ki·ªÉm tra xem c√≥ ch·ª©a t√™n th∆∞∆°ng hi·ªáu ƒë·ªëi th·ªß kh√¥ng
                        competitor_brands_in_data = [
                            'starbucks', 'phuc long', 'highlands', 'katinat', 
                            'trung nguyen', 'coffee house', 'cong ca phe'
                        ]
                        
                        for val in sample_values:
                            if any(brand in val for brand in competitor_brands_in_data):
                                detected_source = 'COMPETITOR'
                                detection_method = f"n·ªôi dung c·ªôt '{column_mapping.get(col, col)}'"
                                break
                        
                        if detected_source:
                            break
            
            # √Åp d·ª•ng k·∫øt qu·∫£ ph√°t hi·ªán (l∆∞u th√¥ng tin ƒë·ªÉ hi·ªÉn th·ªã sau)
            file_detection_info = {
                'source': None,
                'method': None,
                'shop_name': None,
                'has_warning': False
            }
            
            if detected_source:
                file_detection_info['source'] = detected_source
                file_detection_info['method'] = detection_method
                df['source'] = detected_source
                source_col = 'source'
            else:
                # Ph√¢n t√≠ch t√™n file ƒë·ªÉ x√°c ƒë·ªãnh shop/brand c·ª• th·ªÉ
                shop_name = None
                file_name_lower = (file_name or '').lower()
                
                # T√¨m t√™n shop t·ª´ t√™n file
                shop_keywords = {
                    'starbucks': 'STARBUCKS',
                    'phuc long': 'PHUC_LONG',
                    'phuclong': 'PHUC_LONG',
                    'highlands': 'HIGHLANDS',
                    'highland': 'HIGHLANDS',
                    'katinat': 'KATINAT',
                    'trung nguyen': 'TRUNG_NGUYEN',
                    'trungnguyen': 'TRUNG_NGUYEN',
                    'coffee house': 'COFFEE_HOUSE',
                    'cong ca phe': 'CONG_CA_PHE',
                    'congcaphe': 'CONG_CA_PHE',
                    'passio': 'PASSIO',
                    'gong cha': 'GONG_CHA',
                    'gongcha': 'GONG_CHA'
                }
                
                for keyword, shop in shop_keywords.items():
                    if keyword in file_name_lower:
                        shop_name = shop
                        break
                
                if shop_name:
                    file_detection_info['source'] = 'COMPETITOR'
                    file_detection_info['shop_name'] = shop_name
                    file_detection_info['method'] = f"t√™n file '{file_name}'"
                    df['source'] = 'COMPETITOR'
                    source_col = 'source'
                else:
                    # N·∫øu kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c shop c·ª• th·ªÉ
                    # N·∫øu l√† file Menu (c√≥ dummy_review), kh·∫£ nƒÉng cao l√† file c·ªßa User -> M·∫∑c ƒë·ªãnh MY_SHOP
                    if review_col == 'dummy_review' or 'dummy_review' in df.columns:
                         file_detection_info['source'] = 'MY_SHOP'
                         file_detection_info['method'] = "M·∫∑c ƒë·ªãnh (File Menu)"
                         df['source'] = 'MY_SHOP'
                    else:
                         # N·∫øu l√† file Review th√¥ng th∆∞·ªùng m√† kh√¥ng r√µ ngu·ªìn -> COMPETITOR
                         file_detection_info['source'] = 'COMPETITOR'
                         file_detection_info['has_warning'] = True
                         df['source'] = 'COMPETITOR'
                    
                    source_col = 'source'
        
        # B∆∞·ªõc 7: K·∫øt h·ª£p nhi·ªÅu c·ªôt review n·∫øu c√≥
        if review_cols and len(review_cols) > 1:
            # K·∫øt h·ª£p c√°c c·ªôt review l·∫°i th√†nh m·ªôt
            review_parts = []
            for col in review_cols:
                if col != review_col:  # B·ªè qua c·ªôt ch√≠nh ƒë√£ ch·ªçn
                    review_parts.append(df[col].astype(str))
            
            if review_parts:
                # K·∫øt h·ª£p v·ªõi c·ªôt ch√≠nh
                combined_review = df[review_col].astype(str)
                for part in review_parts:
                    # Ch·ªâ th√™m ph·∫ßn kh√¥ng tr·ªëng v√† kh√¥ng tr√πng v·ªõi c·ªôt ch√≠nh
                    part_clean = part.replace('nan', '').str.strip()
                    combined_review = combined_review + ' ' + part_clean
                    combined_review = combined_review.str.strip()
                
                df[review_col] = combined_review
                # L∆∞u th√¥ng tin ƒë·ªÉ hi·ªÉn th·ªã sau (kh√¥ng hi·ªÉn th·ªã ngay)
                if 'combined_cols_info' not in locals():
                    combined_cols_info = {}
                combined_cols_info['count'] = len(review_cols)
                combined_cols_info['cols'] = [column_mapping.get(c, c) for c in review_cols]
        
        # B∆∞·ªõc 7: T√¨m c√°c c·ªôt b·ªï sung (gi√°, menu, rating, v.v.) - M·ªû R·ªòNG
        additional_cols = {}
        
        # T√¨m c·ªôt gi√° - M·ªû R·ªòNG t·ª´ kh√≥a
        price_keywords = [
            'price', 'gi√°', 'cost', 'chi ph√≠', 'amount', 's·ªë ti·ªÅn', 'money', 'gi√° c·∫£',
            'gia', 'don gia', 'ƒë∆°n gi√°', 'gia_ban', 'gia ban', 'price_range', 'pricing',
            'gi√° b√°n', 'gi√° tr·ªã', 'value', 'cost_price', 'selling_price', 'unit_price',
            'gi√° ti·ªÅn', 'tien', 'ti·ªÅn', 'vnd', 'dong', 'ƒë·ªìng', 'usd', 'currency',
            'gia_hien_thi', 'gia hien thi', 'display_price', 'final_price', 'total_price'
        ]
        for col in df.columns:
            if col not in [review_col, source_col]:
                col_lower = col.lower().strip()
                # Ki·ªÉm tra ch√≠nh x√°c ho·∫∑c ch·ª©a t·ª´ kh√≥a
                if any(keyword in col_lower or col_lower == keyword for keyword in price_keywords):
                    # Ki·ªÉm tra xem c·ªôt c√≥ ch·ª©a gi√° tr·ªã s·ªë kh√¥ng
                    if df[col].dtype in ['int64', 'float64'] or pd.to_numeric(df[col], errors='coerce').notna().sum() > len(df) * 0.3:
                        additional_cols['price'] = col
                        break
        
        # T√¨m c·ªôt rating/ƒëi·ªÉm ƒë√°nh gi√° - M·ªû R·ªòNG
        rating_keywords = [
            'rating', 'ƒëi·ªÉm', 'score', 'star', 'sao', 'ƒë√°nh gi√° s·ªë', 'rate',
            'diem', 'danh gia', 'stars', 'rating_score', 'review_score', 'overall_rating',
            'customer_rating', 'user_rating', 'quality_score', 'satisfaction', 'm·ª©c ƒë·ªô h√†i l√≤ng',
            'ƒëi·ªÉm s·ªë', 'diem so', 'ƒë√°nh gi√°', 'danh gia', 'vote', 'votes', 'likes'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                if any(keyword in col_lower or col_lower == keyword for keyword in rating_keywords):
                    additional_cols['rating'] = col
                    break
        
        # T√¨m c·ªôt menu/s·∫£n ph·∫©m - M·ªû R·ªòNG
        menu_keywords = [
            'menu', 'product', 's·∫£n ph·∫©m', 'item', 'm√≥n', 'dish', 'drink', 'ƒë·ªì u·ªëng', 
            'food', 'th·ª©c ƒÉn', 'san pham', 'ten mon', 't√™n m√≥n', 'product_name', 
            'item_name', 'menu_item', 'dish_name', 'product_title', 'item_title',
            't√™n s·∫£n ph·∫©m', 'ten san pham', 'm√≥n ƒÉn', 'mon an', 'ƒë·ªì ƒÉn', 'do an',
            'category', 'danh m·ª•c', 'danh muc', 'type', 'lo·∫°i', 'loai', 'brand', 'th∆∞∆°ng hi·ªáu'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                # Lo·∫°i tr·ª´ c√°c c·ªôt ID/code
                if any(x in col_lower for x in ['code', 'id', 'm√£', 'stt', 'no.', 'order', '_no', '_id']):
                    continue
                if any(keyword in col_lower or col_lower == keyword for keyword in menu_keywords):
                    additional_cols['menu'] = col
                    break
        
        # T√¨m c·ªôt ng√†y th√°ng - M·ªû R·ªòNG
        date_keywords = [
            'date', 'ng√†y', 'time', 'th·ªùi gian', 'created', 'updated', 'timestamp',
            'ngay', 'thoi gian', 'created_at', 'updated_at', 'created_date', 'updated_date',
            'review_date', 'comment_date', 'post_date', 'publish_date', 'datetime', 'date_time',
            'ng√†y ƒë√°nh gi√°', 'ngay danh gia', 'ng√†y t·∫°o', 'ngay tao', 'th·ªùi ƒëi·ªÉm', 'thoi diem'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                if any(keyword in col_lower or col_lower == keyword for keyword in date_keywords):
                    additional_cols['date'] = col
                    break
        
        # T√¨m c·ªôt t√™n kh√°ch h√†ng/user - M·ªû R·ªòNG
        user_keywords = [
            'user', 'customer', 'kh√°ch h√†ng', 'name', 't√™n', 'author', 'ng∆∞·ªùi ƒë√°nh gi√°',
            'khach hang', 'nguoi danh gia', 'reviewer', 'reviewer_name', 'customer_name',
            'user_name', 'username', 'full_name', 't√™n kh√°ch', 'ten khach', 'ng∆∞·ªùi d√πng',
            'nguoi dung', 'buyer', 'purchaser', 'client', 'visitor', 'guest'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                # Lo·∫°i tr·ª´ c√°c c·ªôt c√≥ th·ªÉ nh·∫ßm l·∫´n (nh∆∞ Restaurant Name, Address)
                if any(excluded in col_lower for excluded in ['restaurant', 'shop', 'store', 'address', 'location', 'link']):
                    continue
                if any(keyword in col_lower or col_lower == keyword for keyword in user_keywords):
                    additional_cols['user'] = col
                    break
        
        # T√¨m th√™m c√°c c·ªôt kh√°c c√≥ th·ªÉ h·ªØu √≠ch
        # C·ªôt ƒë·ªãa ch·ªâ/location
        location_keywords = [
            'location', 'address', 'ƒë·ªãa ch·ªâ', 'dia chi', 'place', 'venue', 'v·ªã tr√≠', 'vi tri',
            'city', 'th√†nh ph·ªë', 'thanh pho', 'district', 'qu·∫≠n', 'quan', 'ward', 'ph∆∞·ªùng', 'phuong',
            'street', 'ƒë∆∞·ªùng', 'duong', 'area', 'khu v·ª±c', 'khu vuc'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                if any(keyword in col_lower or col_lower == keyword for keyword in location_keywords):
                    additional_cols['location'] = col
                    break
        
        # C·ªôt s·ªë l∆∞·ª£ng/quantity
        quantity_keywords = [
            'quantity', 'qty', 's·ªë l∆∞·ª£ng', 'so luong', 'amount', 's·ªë', 'so', 'count',
            'quantity_ordered', 'qty_ordered', 'units', 's·ªë ƒë∆°n', 'so don', 'volume'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                if any(keyword in col_lower or col_lower == keyword for keyword in quantity_keywords):
                    additional_cols['quantity'] = col
                    break
        
        # C·ªôt danh m·ª•c/category
        category_keywords = [
            'category', 'danh m·ª•c', 'danh muc', 'type', 'lo·∫°i', 'loai', 'group', 'nh√≥m', 'nhom',
            'classification', 'class', 'tag', 'tags', 'label', 'labels', 'genre', 'th·ªÉ lo·∫°i', 'the loai'
        ]
        for col in df.columns:
            if col not in [review_col, source_col] and col not in additional_cols.values():
                col_lower = col.lower().strip()
                if any(keyword in col_lower or col_lower == keyword for keyword in category_keywords):
                    additional_cols['category'] = col
                    break
        
        # Gi·ªØ l·∫°i T·∫§T C·∫¢ c√°c c·ªôt ƒë·ªÉ kh√¥ng b·ªã m·∫•t d·ªØ li·ªáu quan tr·ªçng cho c√°c b∆∞·ªõc sau (nh∆∞ extract_price_data)
        df_clean = df.copy()
        
        # ƒê·ªïi t√™n c√°c c·ªôt ƒë√£ nh·∫≠n di·ªán ƒë∆∞·ª£c cho chu·∫©n format c·ªßa App
        rename_dict = {review_col: 'review', source_col: 'source'}
        for key, col in additional_cols.items():
            rename_dict[col] = key
        
        # Th·ª±c hi·ªán ƒë·ªïi t√™n
        df_clean = df_clean.rename(columns=rename_dict)
        
        # Lo·∫°i b·ªè d√≤ng c√≥ review tr·ªëng ho·∫∑c ch·ªâ c√≥ kho·∫£ng tr·∫Øng
        df_clean = df_clean[df_clean['review'].notna()]
        df_clean['review'] = df_clean['review'].astype(str).str.strip()
        df_clean = df_clean[df_clean['review'] != '']
        df_clean = df_clean[df_clean['review'].str.lower() != 'nan']
        df_clean = df_clean[df_clean['review'].str.len() > 3]  # √çt nh·∫•t 3 k√Ω t·ª±
        
        # Chu·∫©n h√≥a source (MY_SHOP, COMPETITOR)
        df_clean['source'] = df_clean['source'].astype(str).str.strip().str.upper()
        
        # Mapping c√°c gi√° tr·ªã source ph·ªï bi·∫øn
        source_mapping = {
            'MY_SHOP': 'MY_SHOP',
            'MY SHOP': 'MY_SHOP',
            'C·ª¶A M√åNH': 'MY_SHOP',
            'CUA MINH': 'MY_SHOP',
            'SHOP': 'MY_SHOP',
            'STORE': 'MY_SHOP',
            'BRAND': 'MY_SHOP',
            'COMPETITOR': 'COMPETITOR',
            'COMPETITORS': 'COMPETITOR',
            'ƒê·ªêI TH·ª¶': 'COMPETITOR',
            'DOI THU': 'COMPETITOR',
            'COMPETITION': 'COMPETITOR',
            'RIVAL': 'COMPETITOR'
        }
        
        # √Åp d·ª•ng mapping
        df_clean['source'] = df_clean['source'].replace(source_mapping)
        
        # N·∫øu gi√° tr·ªã kh√¥ng kh·ªõp, m·∫∑c ƒë·ªãnh l√† MY_SHOP
        df_clean['source'] = df_clean['source'].apply(
            lambda x: 'MY_SHOP' if x not in ['MY_SHOP', 'COMPETITOR'] else x
        )
        
        if len(df_clean) == 0:
            # Fallback for Menu Files that might have been filtered out
            # Check if original df had Item and Price
            item_keywords = ['product', 'item', 'dish', 'menu', 'm√≥n', 't√™n m√≥n', 's·∫£n ph·∫©m', 'ten mon', 'san pham']
            price_keywords = ['price', 'cost', 'amount', 'gi√°', 'ƒë∆°n gi√°', 'ti·ªÅn', 'gia', 'don gia']
            
            has_item = any(any(k in col.lower() for k in item_keywords) for col in df.columns)
            has_price = any(any(k in col.lower() for k in price_keywords) for col in df.columns)
            
            if has_item and has_price:
                 # Salvage: Force create dummy review
                 df_clean = df.copy()
                 # Find item col again
                 item_col = next((c for c in df.columns if any(k in c.lower() for k in item_keywords)), df.columns[0])
                 df_clean['review'] = "Menu Item: " + df_clean[item_col].astype(str) + " #" + df_clean.index.astype(str)
                 df_clean['source'] = 'MY_SHOP' # Default
                 return df_clean

            error_msg = f"Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l√†m s·∫°ch. Vui l√≤ng ki·ªÉm tra l·∫°i file.\nDebug Cols: {list(df.columns)}"
            raise ValueError(error_msg)
        
        # Hi·ªÉn th·ªã th√¥ng tin debug chi ti·∫øt
        review_col_original = column_mapping.get(review_col, review_col)
        
        # Ki·ªÉm tra xem source c√≥ ƒë∆∞·ª£c ph√°t hi·ªán t·ª´ t√™n file kh√¥ng
        if source_col == 'source' and source_col not in column_mapping:
            # Ki·ªÉm tra gi√° tr·ªã source th·ª±c t·∫ø trong dataframe
            actual_source = df['source'].iloc[0] if len(df) > 0 else 'COMPETITOR'
            
            # Ki·ªÉm tra xem c√≥ ph√°t hi·ªán t·ª´ t√™n file kh√¥ng
            file_name_lower = (file_name or '').lower()
            competitor_keywords = ['competitor', 'ƒë·ªëi th·ªß', 'starbucks', 'phuc long', 'katinat', 
                                 'highlands', 'trung nguyen', 'shopee', 'lazada', 'grab', 
                                 'now', 'baemin', 'gojek', 'competitors', 'rival']
            my_shop_keywords = ['my_shop', 'c·ªßa m√¨nh', 'my store', 'our shop', 'our store', 'my_']
            
            if any(keyword in file_name_lower for keyword in competitor_keywords):
                source_col_display = f'T·ª± ƒë·ªông t·ª´ t√™n file: COMPETITOR'
            elif any(keyword in file_name_lower for keyword in my_shop_keywords):
                source_col_display = f'T·ª± ƒë·ªông t·ª´ t√™n file: MY_SHOP'
            else:
                # Hi·ªÉn th·ªã source th·ª±c t·∫ø (c√≥ th·ªÉ l√† COMPETITOR n·∫øu kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c MY_SHOP)
                source_col_display = f'T·ª± ƒë·ªông: {actual_source}'
        else:
            source_col_display = column_mapping.get(source_col, source_col)
        
        # L∆∞u th√¥ng tin file ƒë·ªÉ hi·ªÉn th·ªã sau (kh√¥ng hi·ªÉn th·ªã ngay)
        file_summary = {
            'name': file_name,
            'review_cols_count': len(review_cols),
            'source': source_col_display.split(':')[-1].strip(),
            'additional_cols_count': len(additional_cols),
            'total_cols': len(original_columns),
            'review_col': review_col_original,
            'other_cols': [column_mapping.get(c, c) for c in review_cols if c != review_col] if len(review_cols) > 1 else [],
            'combined_cols_info': combined_cols_info if 'combined_cols_info' in locals() else None,
            'additional_cols': {k: column_mapping.get(v, v) for k, v in additional_cols.items()} if additional_cols else {},
            'has_warning': file_detection_info.get('has_warning', False) if 'file_detection_info' in locals() else False
        }
        
        # L∆∞u v√†o session state ƒë·ªÉ app.py hi·ªÉn th·ªã
        if 'file_summaries' not in st.session_state:
            st.session_state['file_summaries'] = []
        st.session_state['file_summaries'].append(file_summary)
        
        return df_clean.reset_index(drop=True)
    
    except Exception as e:
        raise Exception(f"L·ªói khi ƒë·ªçc file: {str(e)}")


def prepare_reviews_for_ai(df: pd.DataFrame, max_reviews: int = 500) -> List[Dict[str, Any]]:
    """
    Chuy·ªÉn ƒë·ªïi DataFrame th√†nh format ƒë·ªÉ g·ª≠i cho AI
    T·ªëi ∆∞u h√≥a ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu d·ªØ li·ªáu h∆°n, bao g·ªìm c·∫£ c√°c th√¥ng tin b·ªï sung
    CH·ªåN L·ªåC TH√îNG MINH: ∆Øu ti√™n reviews c√≥ nhi·ªÅu th√¥ng tin, ƒëa d·∫°ng, v√† quan tr·ªçng
    
    Args:
        df: DataFrame ƒë√£ l√†m s·∫°ch (c√≥ th·ªÉ c√≥ th√™m c√°c c·ªôt: price, rating, menu, date, user)
        max_reviews: S·ªë l∆∞·ª£ng review t·ªëi ƒëa ƒë·ªÉ g·ª≠i (500 ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu d·ªØ li·ªáu h∆°n)
    
    Returns:
        List c√°c dict v·ªõi keys: 'review', 'source', v√† c√°c keys kh√°c n·∫øu c√≥ (price, rating, menu, v.v.)
    """
    total_reviews = len(df)
    
    # N·∫øu c√≥ qu√° nhi·ªÅu reviews, s·ª≠ d·ª•ng sampling th√¥ng minh v·ªõi ch·ªçn l·ªçc t·ªët h∆°n
    if total_reviews > max_reviews:
        # T√≠nh ƒëi·ªÉm ∆∞u ti√™n cho m·ªói review (scoring system)
        df = df.copy()
        df['_priority_score'] = 0
        
        # 1. ƒêi·ªÉm cho ƒë·ªô d√†i review (reviews d√†i th∆∞·ªùng c√≥ nhi·ªÅu th√¥ng tin h∆°n)
        df['_review_length'] = df['review'].astype(str).str.len()
        df['_priority_score'] += df['_review_length'].apply(lambda x: min(x / 100, 5))  # T·ªëi ƒëa 5 ƒëi·ªÉm
        
        # 2. ƒêi·ªÉm cho th√¥ng tin b·ªï sung (c√≥ price, rating, menu, date, user)
        info_columns = ['price', 'rating', 'menu', 'date', 'user', 'location', 'quantity', 'category']
        for col in info_columns:
            if col in df.columns:
                df['_priority_score'] += df[col].notna().astype(int) * 2  # M·ªói th√¥ng tin b·ªï sung = 2 ƒëi·ªÉm
        
        # 3. ƒêi·ªÉm cho rating (reviews c√≥ rating cao ho·∫∑c th·∫•p ƒë·ªÅu quan tr·ªçng)
        if 'rating' in df.columns:
            # Chuy·ªÉn rating sang s·ªë n·∫øu c√≥ th·ªÉ
            df['_rating_num'] = pd.to_numeric(df['rating'], errors='coerce')
            # ∆Øu ti√™n rating c·ª±c cao (5) ho·∫∑c c·ª±c th·∫•p (1-2) v√¨ ch√∫ng c√≥ insights r√µ r√†ng
            df['_priority_score'] += df['_rating_num'].apply(
                lambda x: 3 if pd.notna(x) and (x >= 4.5 or x <= 2) else (1 if pd.notna(x) else 0)
            )
        
        # 4. ƒêi·ªÉm cho ƒë·ªô ƒëa d·∫°ng (tr√°nh ch·ªçn nhi·ªÅu reviews gi·ªëng nhau)
        # S·ª≠ d·ª•ng hash c·ªßa review ƒë·ªÉ nh√≥m c√°c reviews t∆∞∆°ng t·ª±
        df['_review_hash'] = df['review'].astype(str).str.lower().str.strip().apply(hash)
        
        # 5. ƒêi·ªÉm cho t·ª´ kh√≥a quan tr·ªçng (t·ª´ kh√≥a li√™n quan ƒë·∫øn SWOT)
        important_keywords = [
            't·ªët', 'tuy·ªát', 'xu·∫•t s·∫Øc', 't·ªá', 'k√©m', 'ch·∫≠m', 'nhanh', 'ƒë·∫Øt', 'r·∫ª', 'gi√°',
            'nh√¢n vi√™n', 'ph·ª•c v·ª•', 'd·ªãch v·ª•', 'ch·∫•t l∆∞·ª£ng', 'ngon', 'd·ªü', 's·∫°ch', 'b·∫©n',
            'kh√¥ng gian', 'v·ªã tr√≠', 'thu·∫≠n ti·ªán', 'ƒë√¥ng', 'v·∫Øng', 'y√™n tƒ©nh', '·ªìn √†o',
            'ƒë·ªÅ xu·∫•t', 'khuy√™n', 'kh√¥ng n√™n', 'tr√°nh', 'n√™n th·ª≠', 'quay l·∫°i', 'kh√¥ng quay l·∫°i',
            'good', 'excellent', 'bad', 'poor', 'slow', 'fast', 'expensive', 'cheap', 'price',
            'staff', 'service', 'quality', 'delicious', 'dirty', 'clean', 'space', 'location'
        ]
        df['_keyword_count'] = df['review'].astype(str).str.lower().apply(
            lambda x: sum(1 for kw in important_keywords if kw in x)
        )
        df['_priority_score'] += df['_keyword_count'] * 0.5  # M·ªói t·ª´ kh√≥a = 0.5 ƒëi·ªÉm
        
        # T√°ch MY_SHOP v√† COMPETITOR ƒë·ªÉ ch·ªçn l·ªçc ri√™ng
        my_shop_df = df[df['source'] == 'MY_SHOP'].copy()
        competitor_df = df[df['source'] == 'COMPETITOR'].copy()
        
        # T√≠nh t·ª∑ l·ªá ƒë·ªÉ gi·ªØ c√¢n b·∫±ng
        my_shop_ratio = len(my_shop_df) / total_reviews if total_reviews > 0 else 0.5
        competitor_ratio = len(competitor_df) / total_reviews if total_reviews > 0 else 0.5
        
        # L·∫•y m·∫´u th√¥ng minh cho MY_SHOP
        my_shop_sample_size = int(max_reviews * my_shop_ratio)
        if len(my_shop_df) > 0 and my_shop_sample_size > 0:
            # S·∫Øp x·∫øp theo priority score v√† ch·ªçn ƒëa d·∫°ng
            my_shop_df = my_shop_df.sort_values('_priority_score', ascending=False)
            
            # Ch·ªçn top reviews nh∆∞ng ƒë·∫£m b·∫£o ƒëa d·∫°ng (kh√¥ng ch·ªçn qu√° nhi·ªÅu reviews gi·ªëng nhau)
            selected_my_shop = []
            seen_hashes = set()
            
            for _, row in my_shop_df.iterrows():
                if len(selected_my_shop) >= my_shop_sample_size:
                    break
                # Ch·ªâ th√™m n·∫øu ch∆∞a c√≥ review t∆∞∆°ng t·ª± (hash kh√°c)
                review_hash = row['_review_hash']
                if review_hash not in seen_hashes:
                    selected_my_shop.append(row)
                    seen_hashes.add(review_hash)
                elif len(selected_my_shop) < my_shop_sample_size * 0.8:  # Cho ph√©p 20% tr√πng l·∫∑p
                    selected_my_shop.append(row)
            
            my_shop_sample = pd.DataFrame(selected_my_shop)
        else:
            my_shop_sample = pd.DataFrame()
        
        # L·∫•y m·∫´u th√¥ng minh cho COMPETITOR
        competitor_sample_size = max_reviews - len(my_shop_sample)
        if len(competitor_df) > 0 and competitor_sample_size > 0:
            # S·∫Øp x·∫øp theo priority score
            competitor_df = competitor_df.sort_values('_priority_score', ascending=False)
            
            # Ch·ªçn top reviews nh∆∞ng ƒë·∫£m b·∫£o ƒëa d·∫°ng
            selected_competitor = []
            seen_hashes = set()
            
            for _, row in competitor_df.iterrows():
                if len(selected_competitor) >= competitor_sample_size:
                    break
                review_hash = row['_review_hash']
                if review_hash not in seen_hashes:
                    selected_competitor.append(row)
                    seen_hashes.add(review_hash)
                elif len(selected_competitor) < competitor_sample_size * 0.8:
                    selected_competitor.append(row)
            
            competitor_sample = pd.DataFrame(selected_competitor)
        else:
            competitor_sample = pd.DataFrame()
        
        # K·∫øt h·ª£p l·∫°i
        if len(my_shop_sample) > 0 and len(competitor_sample) > 0:
            df = pd.concat([my_shop_sample, competitor_sample], ignore_index=True)
        elif len(my_shop_sample) > 0:
            df = my_shop_sample
        elif len(competitor_sample) > 0:
            df = competitor_sample
        else:
            # Fallback: ch·ªçn top reviews theo priority score
            df = df.nlargest(max_reviews, '_priority_score')
        
        # X√≥a c√°c c·ªôt t·∫°m
        df = df.drop(columns=[col for col in df.columns if col.startswith('_')])
        
        st.info(f"üìä ƒê√£ ch·ªçn l·ªçc {len(df):,} reviews quan tr·ªçng nh·∫•t t·ª´ {total_reviews:,} reviews (∆∞u ti√™n reviews c√≥ nhi·ªÅu th√¥ng tin, ƒëa d·∫°ng, v√† c√≥ t·ª´ kh√≥a quan tr·ªçng).")
    
    # Detect smart column mappings - M·ªû R·ªòNG ƒë·ªÉ nh·∫≠n di·ªán nhi·ªÅu c·ªôt h∆°n
    col_mapping = {}
    
    # Keyword lists (enhanced - m·ªü r·ªông ƒë·ªÉ nh·∫≠n di·ªán nhi·ªÅu c·ªôt h∆°n)
    price_keywords = [
        'price', 'cost', 'amount', 'gi√°', 'ƒë∆°n gi√°', 'chi ph√≠', 'ti·ªÅn', 'gia', 'don gia', 'gia_ban',
        'gia hien thi', 'gia_hien_thi', 'display_price', 'final_price', 'total_price', 'selling_price',
        'unit_price', 'cost_price', 'price_range', 'pricing', 'gi√° b√°n', 'gi√° tr·ªã', 'value', 'vnd', 'dong'
    ]
    menu_keywords = [
        'product', 'item', 'dish', 'menu', 'm√≥n', 't√™n m√≥n', 's·∫£n ph·∫©m', 'food', 'drink', 'name', 't√™n', 
        'ten mon', 'san pham', 'product_name', 'item_name', 'menu_item', 'dish_name', 'product_title',
        't√™n s·∫£n ph·∫©m', 'ten san pham', 'm√≥n ƒÉn', 'mon an', 'ƒë·ªì ƒÉn', 'do an', 'category', 'danh m·ª•c',
        'type', 'lo·∫°i', 'loai', 'brand', 'th∆∞∆°ng hi·ªáu'
    ]
    rating_keywords = [
        'rating', 'score', 'star', 'ƒëi·ªÉm', 'sao', 'ƒë√°nh gi√°', 'danh gia', 'diem', 'stars', 'rating_score',
        'review_score', 'overall_rating', 'customer_rating', 'user_rating', 'quality_score', 'satisfaction',
        'ƒëi·ªÉm s·ªë', 'diem so', 'vote', 'votes', 'likes'
    ]
    date_keywords = [
        'date', 'time', 'ng√†y', 'gi·ªù', 'th·ªùi gian', 'ngay', 'created_at', 'updated_at', 'created_date',
        'updated_date', 'review_date', 'comment_date', 'post_date', 'publish_date', 'datetime', 'date_time',
        'ng√†y ƒë√°nh gi√°', 'ngay danh gia', 'ng√†y t·∫°o', 'ngay tao', 'th·ªùi ƒëi·ªÉm', 'thoi diem'
    ]
    user_keywords = [
        'user', 'customer', 'name', 'kh√°ch', 'ng∆∞·ªùi d√πng', 't√™n kh√°ch', 'khach hang', 'nguoi danh gia',
        'reviewer', 'reviewer_name', 'customer_name', 'user_name', 'username', 'full_name', 't√™n kh√°ch',
        'ten khach', 'ng∆∞·ªùi d√πng', 'nguoi dung', 'buyer', 'purchaser', 'client', 'visitor', 'guest'
    ]
    location_keywords = [
        'location', 'address', 'ƒë·ªãa ch·ªâ', 'dia chi', 'place', 'venue', 'v·ªã tr√≠', 'vi tri',
        'city', 'th√†nh ph·ªë', 'thanh pho', 'district', 'qu·∫≠n', 'quan', 'ward', 'ph∆∞·ªùng', 'phuong'
    ]
    quantity_keywords = [
        'quantity', 'qty', 's·ªë l∆∞·ª£ng', 'so luong', 'amount', 's·ªë', 'so', 'count',
        'quantity_ordered', 'qty_ordered', 'units', 's·ªë ƒë∆°n', 'so don', 'volume'
    ]
    category_keywords = [
        'category', 'danh m·ª•c', 'danh muc', 'type', 'lo·∫°i', 'loai', 'group', 'nh√≥m', 'nhom',
        'classification', 'class', 'tag', 'tags', 'label', 'labels', 'genre', 'th·ªÉ lo·∫°i', 'the loai'
    ]
    
    # Find best matching columns if standard names don't exist
    # M·ªü r·ªông ƒë·ªÉ t√¨m nhi·ªÅu lo·∫°i c·ªôt h∆°n
    for target, keywords in [
        ('price', price_keywords), 
        ('menu', menu_keywords), 
        ('rating', rating_keywords),
        ('date', date_keywords), 
        ('user', user_keywords),
        ('location', location_keywords),
        ('quantity', quantity_keywords),
        ('category', category_keywords)
    ]:
        if target in df.columns:
             col_mapping[target] = target
        else:
             # Find first matching column (case-insensitive, flexible matching)
             match = next((c for c in df.columns if any(k in c.lower().strip() for k in keywords)), None)
             if match:
                 col_mapping[target] = match

    reviews_list = []
    for _, row in df.iterrows():
        review_dict = {
            'review': str(row['review']),
            'source': str(row['source'])
        }
        
        # Add additional info using mapped columns
        for target_key, df_col in col_mapping.items():
            if pd.notna(row[df_col]):
                review_dict[target_key] = row[df_col]
        
        reviews_list.append(review_dict)
    
    return reviews_list


def create_swot_pie_chart(swot_data: Dict[str, Any]) -> go.Figure:
    """
    T·∫°o bi·ªÉu ƒë·ªì tr√≤n hi·ªÉn th·ªã s·ªë l∆∞·ª£ng items trong m·ªói nh√≥m SWOT
    
    Args:
        swot_data: Dict ch·ª©a SWOT_Analysis
    
    Returns:
        Plotly Figure object
    """
    swot = swot_data.get("SWOT_Analysis", {})
    
    categories = ['Strengths', 'Weaknesses', 'Opportunities', 'Threats']
    counts = [
        len(swot.get("Strengths", [])),
        len(swot.get("Weaknesses", [])),
        len(swot.get("Opportunities", [])),
        len(swot.get("Threats", []))
    ]
    
    colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12']  # Xanh l√°, ƒê·ªè, Xanh d∆∞∆°ng, V√†ng
    
    fig = go.Figure(data=[go.Pie(
        labels=categories,
        values=counts,
        hole=0.4,
        marker_colors=colors,
        textinfo='label+percent+value',
        textfont_size=12
    )])
    
    fig.update_layout(
        title={
            'text': 'Ph√¢n b·ªë SWOT Analysis',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18}
        },
        showlegend=True,
        height=400
    )
    
    return fig


def create_impact_bar_chart(swot_data: Dict[str, Any]) -> go.Figure:
    """
    T·∫°o bi·ªÉu ƒë·ªì c·ªôt hi·ªÉn th·ªã ph√¢n b·ªë Impact/Risk Level
    
    Args:
        swot_data: Dict ch·ª©a SWOT_Analysis
    
    Returns:
        Plotly Figure object
    """
    swot = swot_data.get("SWOT_Analysis", {})
    
    impact_levels = {'High': 0, 'Medium': 0, 'Low': 0}
    
    # ƒê·∫øm Strengths v√† Weaknesses theo impact
    for item in swot.get("Strengths", []):
        impact = item.get("impact", "Medium")
        if impact in impact_levels:
            impact_levels[impact] += 1
    
    for item in swot.get("Weaknesses", []):
        impact = item.get("impact", "Medium")
        if impact in impact_levels:
            impact_levels[impact] += 1
    
    # ƒê·∫øm Threats theo risk_level
    for item in swot.get("Threats", []):
        risk = item.get("risk_level", "Medium")
        if risk in impact_levels:
            impact_levels[risk] += 1
    
    fig = go.Figure(data=[
        go.Bar(
            x=list(impact_levels.keys()),
            y=list(impact_levels.values()),
            marker_color=['#e74c3c', '#f39c12', '#2ecc71'],  # ƒê·ªè, V√†ng, Xanh l√°
            text=list(impact_levels.values()),
            textposition='auto'
        )
    ])
    
    fig.update_layout(
        title={
            'text': 'Ph√¢n b·ªë M·ª©c ƒë·ªô ·∫¢nh h∆∞·ªüng/R·ªßi ro',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18}
        },
        xaxis_title='M·ª©c ƒë·ªô',
        yaxis_title='S·ªë l∆∞·ª£ng',
        height=400
    )
    
    return fig


def format_swot_table_data(swot_data: Dict[str, Any], category: str) -> List[Dict[str, str]]:
    """
    Format d·ªØ li·ªáu SWOT ƒë·ªÉ hi·ªÉn th·ªã trong b·∫£ng Streamlit
    
    Args:
        swot_data: Dict ch·ª©a SWOT_Analysis
        category: 'Strengths', 'Weaknesses', 'Opportunities', ho·∫∑c 'Threats'
    
    Returns:
        List c√°c dict ƒë√£ format
    """
    swot = swot_data.get("SWOT_Analysis", {})
    items = swot.get(category, [])
    
    formatted_items = []
    for item in items:
        formatted_item = {
            "Ch·ªß ƒë·ªÅ": item.get("topic", "N/A"),
            "M√¥ t·∫£": item.get("description", "N/A")
        }
        
        # Th√™m priority score n·∫øu c√≥
        if "priority_score" in item:
            formatted_item["ƒêi·ªÉm ∆∞u ti√™n"] = item.get("priority_score", "N/A")
        
        # Th√™m c√°c tr∆∞·ªùng ƒë·∫∑c bi·ªát
        if category == "Strengths":
            formatted_item["M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng"] = item.get("impact", "N/A")
            formatted_item["Chi·∫øn l∆∞·ª£c t·∫≠n d·ª•ng"] = item.get("leverage_strategy", "N/A")
        
        if category == "Weaknesses":
            formatted_item["M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng"] = item.get("impact", "N/A")
            formatted_item["Nguy√™n nh√¢n g·ªëc r·ªÖ"] = item.get("root_cause", "N/A")
            formatted_item["K·∫ø ho·∫°ch kh·∫Øc ph·ª•c"] = item.get("mitigation_plan", "N/A")
        
        if category == "Opportunities":
            formatted_item["G·ª£i √Ω h√†nh ƒë·ªông"] = item.get("action_idea", "N/A")
            formatted_item["Quy m√¥ th·ªã tr∆∞·ªùng"] = item.get("market_size", "N/A")
            formatted_item["Th·ªùi gian n·∫Øm b·∫Øt"] = item.get("time_to_capture", "N/A")
        
        if category == "Threats":
            formatted_item["M·ª©c ƒë·ªô r·ªßi ro"] = item.get("risk_level", "N/A")
            formatted_item["X√°c su·∫•t"] = item.get("probability", "N/A")
            formatted_item["M·ª©c ƒë·ªô nghi√™m tr·ªçng"] = item.get("severity", "N/A")
            formatted_item["K·∫ø ho·∫°ch ·ª©ng ph√≥"] = item.get("contingency_plan", "N/A")
        
        formatted_items.append(formatted_item)
    
    return formatted_items


# ========== ENTERPRISE VISUALIZATIONS ==========

def create_tows_matrix_chart(tows_data: Dict[str, List]) -> go.Figure:
    """
    T·∫°o bi·ªÉu ƒë·ªì TOWS Matrix 2x2
    
    Args:
        tows_data: Dict ch·ª©a SO_Strategies, WO_Strategies, ST_Strategies, WT_Strategies
    
    Returns:
        Plotly Figure object
    """
    # Count strategies in each quadrant
    so_count = len(tows_data.get('SO_Strategies', []))
    wo_count = len(tows_data.get('WO_Strategies', []))
    st_count = len(tows_data.get('ST_Strategies', []))
    wt_count = len(tows_data.get('WT_Strategies', []))
    
    # Create heatmap data
    z = [[so_count, st_count],
         [wo_count, wt_count]]
    
    x_labels = ['Opportunities', 'Threats']
    y_labels = ['Strengths', 'Weaknesses']
    
    # Create text for each cell
    text = [
        [f"SO Strategies<br>{so_count} chi·∫øn l∆∞·ª£c<br>(T·∫•n c√¥ng)", 
         f"ST Strategies<br>{st_count} chi·∫øn l∆∞·ª£c<br>(ƒêa d·∫°ng h√≥a)"],
        [f"WO Strategies<br>{wo_count} chi·∫øn l∆∞·ª£c<br>(Chuy·ªÉn ƒë·ªïi)", 
         f"WT Strategies<br>{wt_count} chi·∫øn l∆∞·ª£c<br>(Ph√≤ng th·ªß)"]
    ]
    
    fig = go.Figure(data=go.Heatmap(
        z=z,
        x=x_labels,
        y=y_labels,
        text=text,
        texttemplate="%{text}",
        textfont={"size": 12},
        colorscale=[[0, '#3498db'], [0.5, '#9b59b6'], [1, '#e74c3c']],
        showscale=True,
        hoverongaps=False
    ))
    
    fig.update_layout(
        title={
            'text': 'üìä Ma tr·∫≠n TOWS - Chi·∫øn l∆∞·ª£c K·∫øt h·ª£p',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18}
        },
        xaxis_title='Y·∫øu t·ªë B√™n ngo√†i',
        yaxis_title='Y·∫øu t·ªë N·ªôi b·ªô',
        height=450,
        xaxis={'side': 'top'}
    )
    
    return fig


def create_priority_heatmap(swot_data: Dict[str, Any]) -> go.Figure:
    """
    T·∫°o Priority Matrix Heatmap (Impact vs Feasibility)
    
    Args:
        swot_data: Dict ch·ª©a SWOT_Analysis v·ªõi priority_score
    
    Returns:
        Plotly Figure object
    """
    swot = swot_data.get("SWOT_Analysis", {})
    
    items = []
    for category in ['Strengths', 'Weaknesses', 'Opportunities', 'Threats']:
        for item in swot.get(category, []):
            items.append({
                'topic': item.get('topic', 'N/A'),  # Full topic for hover
                'category': category,
                'priority_score': item.get('priority_score', 5),
                'impact': item.get('impact') or item.get('risk_level', 'Medium')
            })

    
    if not items:
        # Return empty figure if no data
        fig = go.Figure()
        fig.add_annotation(text="Kh√¥ng c√≥ d·ªØ li·ªáu", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    df_items = pd.DataFrame(items)
    
    # Map impact to numeric
    impact_map = {'High': 3, 'Medium': 2, 'Low': 1}
    df_items['impact_score'] = df_items['impact'].map(impact_map).fillna(2)
    
    # Map category to color
    color_map = {
        'Strengths': '#2ecc71',
        'Weaknesses': '#e74c3c', 
        'Opportunities': '#3498db',
        'Threats': '#f39c12'
    }
    df_items['color'] = df_items['category'].map(color_map)
    
    # Add jitter to avoid overlapping points
    import numpy as np
    np.random.seed(42)
    df_items['impact_jitter'] = df_items['impact_score'] + np.random.uniform(-0.15, 0.15, len(df_items))
    df_items['priority_jitter'] = df_items['priority_score'] + np.random.uniform(-0.2, 0.2, len(df_items))
    
    fig = go.Figure()
    
    for category in ['Strengths', 'Weaknesses', 'Opportunities', 'Threats']:
        df_cat = df_items[df_items['category'] == category]
        if not df_cat.empty:
            fig.add_trace(go.Scatter(
                x=df_cat['impact_jitter'],
                y=df_cat['priority_jitter'],
                mode='markers',
                marker=dict(
                    size=16,
                    color=color_map[category],
                    line=dict(width=2, color='white'),
                    opacity=0.85
                ),
                name=category,
                customdata=df_cat['topic'],
                hovertemplate='<b>%{customdata}</b><br>Impact: %{x:.0f}<br>Priority: %{y:.1f}<extra></extra>'
            ))
    
    # Add quadrant lines
    fig.add_hline(y=5, line_dash="dash", line_color="gray", opacity=0.5)
    fig.add_vline(x=2, line_dash="dash", line_color="gray", opacity=0.5)
    
    # Add quadrant labels - positioned inside chart area with smaller text
    fig.add_annotation(x=2.5, y=8.5, text="∆Øu ti√™n cao", showarrow=False, font=dict(size=10, color="#27ae60"))
    fig.add_annotation(x=1.5, y=8.5, text="Theo d√µi", showarrow=False, font=dict(size=10, color="#3498db"))
    fig.add_annotation(x=2.5, y=1.5, text="Quick Wins", showarrow=False, font=dict(size=10, color="#f39c12"))
    fig.add_annotation(x=1.5, y=1.5, text="Backlog", showarrow=False, font=dict(size=10, color="#95a5a6"))
    
    fig.update_layout(
        title={
            'text': 'Ma tr·∫≠n ∆Øu ti√™n (Impact vs Priority Score)',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 14}
        },
        xaxis_title='M·ª©c ƒë·ªô ·∫¢nh h∆∞·ªüng',
        yaxis_title='ƒêi·ªÉm ∆Øu ti√™n',
        xaxis=dict(
            tickmode='array', 
            tickvals=[1, 2, 3], 
            ticktext=['Low', 'Medium', 'High'], 
            range=[0.8, 3.2]  # Tighter range
        ),
        yaxis=dict(range=[0, 10]),
        height=500,
        margin=dict(l=60, r=40, t=80, b=60),  # Better margins
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="center",
            x=0.5
        ),
        hovermode='closest'
    )
    
    return fig





def create_competitive_radar(competitive_data: Dict[str, Any]) -> go.Figure:
    """
    T·∫°o Radar Chart so s√°nh c·∫°nh tranh
    
    Args:
        competitive_data: Dict ch·ª©a my_scores v√† competitor_scores
    
    Returns:
        Plotly Figure object
    """
    dimensions = competitive_data.get('dimensions', ['quality', 'price', 'service', 'location', 'brand', 'innovation'])
    my_scores = competitive_data.get('my_scores', {})
    competitor_scores = competitive_data.get('competitor_scores', {})
    
    # Vietnamese labels
    label_map = {
        'quality': 'Ch·∫•t l∆∞·ª£ng',
        'price': 'Gi√° c·∫£',
        'service': 'D·ªãch v·ª•',
        'location': 'V·ªã tr√≠',
        'brand': 'Th∆∞∆°ng hi·ªáu',
        'innovation': 'ƒê·ªïi m·ªõi'
    }
    
    labels = [label_map.get(d, d) for d in dimensions]
    
    my_values = [my_scores.get(d, 5) for d in dimensions]
    comp_values = [competitor_scores.get(d, 5) for d in dimensions]
    
    # Close the radar chart
    labels.append(labels[0])
    my_values.append(my_values[0])
    comp_values.append(comp_values[0])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=my_values,
        theta=labels,
        fill='toself',
        fillcolor='rgba(46, 204, 113, 0.3)',
        line=dict(color='#2ecc71', width=2),
        name='Qu√°n c·ªßa b·∫°n'
    ))
    
    fig.add_trace(go.Scatterpolar(
        r=comp_values,
        theta=labels,
        fill='toself',
        fillcolor='rgba(231, 76, 60, 0.3)',
        line=dict(color='#e74c3c', width=2),
        name='ƒê·ªëi th·ªß trung b√¨nh'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 10],
                tickmode='array',
                tickvals=[2, 4, 6, 8, 10]
            )
        ),
        title={
            'text': 'So s√°nh V·ªã th·∫ø C·∫°nh tranh',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 16}
        },
        showlegend=True,
        height=500
    )
    
    return fig


def create_risk_matrix(risk_data: List[Dict]) -> go.Figure:
    """
    T·∫°o Risk Matrix (Probability vs Severity)
    
    Args:
        risk_data: List c√°c threats v·ªõi probability v√† severity
    
    Returns:
        Plotly Figure object
    """
    if not risk_data:
        fig = go.Figure()
        fig.add_annotation(text="Kh√¥ng c√≥ d·ªØ li·ªáu r·ªßi ro", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # Map levels to numeric
    level_map = {'High': 3, 'Medium': 2, 'Low': 1}
    
    x_vals = []
    y_vals = []
    texts = []
    colors = []
    
    for risk in risk_data:
        prob = level_map.get(risk.get('probability', 'Medium'), 2)
        sev = level_map.get(risk.get('severity', risk.get('risk_level', 'Medium')), 2)
        
        x_vals.append(prob)
        y_vals.append(sev)
        texts.append(risk.get('topic', 'N/A'))  # Full text for hover
        
        # Color based on composite risk
        risk_score = prob * sev
        if risk_score >= 6:
            colors.append('#e74c3c')  # Red - Critical
        elif risk_score >= 4:
            colors.append('#f39c12')  # Orange - High
        else:
            colors.append('#2ecc71')  # Green - Low
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=x_vals,
        y=y_vals,
        mode='markers+text',
        marker=dict(
            size=20,
            color=colors,
            line=dict(width=2, color='white')
        ),
        text=texts,
        textposition='top center',
        hovertemplate='%{text}<br>Probability: %{x}<br>Severity: %{y}<extra></extra>'
    ))
    
    # Add background zones
    fig.add_shape(type="rect", x0=0.5, y0=2.5, x1=1.5, y1=3.5, fillcolor="rgba(46, 204, 113, 0.2)", line_width=0)
    fig.add_shape(type="rect", x0=2.5, y0=0.5, x1=3.5, y1=1.5, fillcolor="rgba(46, 204, 113, 0.2)", line_width=0)
    fig.add_shape(type="rect", x0=2.5, y0=2.5, x1=3.5, y1=3.5, fillcolor="rgba(231, 76, 60, 0.2)", line_width=0)
    
    fig.update_layout(
        title={
            'text': '‚ö†Ô∏è Ma tr·∫≠n ƒê√°nh gi√° R·ªßi ro',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18}
        },
        xaxis_title='X√°c su·∫•t x·∫£y ra',
        yaxis_title='M·ª©c ƒë·ªô nghi√™m tr·ªçng',
        xaxis=dict(tickmode='array', tickvals=[1, 2, 3], ticktext=['Th·∫•p', 'Trung b√¨nh', 'Cao'], range=[0.5, 3.5]),
        yaxis=dict(tickmode='array', tickvals=[1, 2, 3], ticktext=['Th·∫•p', 'Trung b√¨nh', 'Cao'], range=[0.5, 3.5]),
        height=450
    )
    
    return fig


def create_action_timeline(action_plan: List[Dict]) -> go.Figure:
    """
    T·∫°o Timeline cho Action Plan
    
    Args:
        action_plan: List c√°c actions v·ªõi timeline
    
    Returns:
        Plotly Figure object
    """
    if not action_plan:
        fig = go.Figure()
        fig.add_annotation(text="Kh√¥ng c√≥ k·∫ø ho·∫°ch h√†nh ƒë·ªông", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # Group actions by timeline
    timeline_groups = {}
    for action in action_plan:
        timeline = action.get('timeline', 'Q1 2026')
        if timeline not in timeline_groups:
            timeline_groups[timeline] = []
        timeline_groups[timeline].append(action)
    
    # Sort timelines
    sorted_timelines = sorted(timeline_groups.keys())
    
    # Create horizontal bar chart
    actions = []
    priorities = []
    colors = []
    timelines = []
    
    color_map = {
        'Leverage Strength': '#2ecc71',
        'Address Weakness': '#e74c3c',
        'Capture Opportunity': '#3498db',
        'Mitigate Threat': '#f39c12'
    }
    
    for action in action_plan[:15]:  # Limit to 15 actions
        actions.append(action.get('action', 'N/A'))  # Full text for display
        priorities.append(action.get('priority', 10))
        colors.append(color_map.get(action.get('type', ''), '#95a5a6'))
        timelines.append(action.get('timeline', 'N/A'))
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        y=actions[::-1],  # Reverse for proper display
        x=priorities[::-1],
        orientation='h',
        marker=dict(color=colors[::-1]),
        text=timelines[::-1],
        textposition='inside',
        hovertemplate='%{y}<br>Priority: %{x}<br>Timeline: %{text}<extra></extra>'
    ))
    
    fig.update_layout(
        title={
            'text': 'K·∫ø ho·∫°ch H√†nh ƒë·ªông theo ∆Øu ti√™n',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 16}
        },
        xaxis_title='M·ª©c ƒë·ªô ∆Øu ti√™n',
        yaxis_title='',
        height=max(500, len(actions) * 40),
        margin=dict(l=350, r=40, t=60, b=60),  # Wide left margin for full text
        showlegend=False,
        xaxis=dict(range=[0, max(priorities) + 1])
    )

    
    return fig

def extract_price_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    T·ª± ƒë·ªông tr√≠ch xu·∫•t d·ªØ li·ªáu gi√° t·ª´ DataFrame n·∫øu c√≥
    
    Returns:
        DataFrame columns: ['M√≥n', 'Gi√° c·ªßa b·∫°n', 'Gi√° ƒë·ªëi th·ªß'] ho·∫∑c Empty DataFrame
    """
    if df is None or df.empty:
        return pd.DataFrame()
        
    # 1. T√¨m c·ªôt Item/Product
    # Th√™m keywords 'name', 'desc' ƒë·ªÉ fallback n·∫øu c·ªôt 'Item' b·ªã lo·∫°i do l√† ID
    # Th√™m unaccented keywords: 'ten mon', 'san pham'
    item_keywords = ['product', 'item', 'dish', 'menu', 'm√≥n', 't√™n m√≥n', 's·∫£n ph·∫©m', 'food', 'drink', 'name', 't√™n', 'desc', 'm√¥ t·∫£', 'ten mon', 'san pham']
    item_candidates = []
    
    debug_rejections = [] # DEBUG

    for col in df.columns:
        col_lower = col.lower()
        # Exclude ID/Code columns by Name
        exclude_match = [x for x in ['code', 'id', 'm√£', 'stt', 'no.', 'order', '_no', '_id'] if x in col_lower]
        if exclude_match:
            debug_rejections.append(f"Col '{col}' rejected by name filter: {exclude_match}")
            continue
            
        if any(k in col_lower for k in item_keywords) and df[col].dtype == 'object':
            # Critical: Check CONTENT to avoid numeric IDs that escaped name filter
            try:
                # Sample 50 values (increased from 20)
                sample = df[col].dropna().head(50)
                if len(sample) > 0:
                    # Check if mostly numeric
                    numeric_ratio = pd.to_numeric(sample, errors='coerce').notna().mean()
                    
                    # Log debug info
                    # debug_rejections.append(f"Candidate '{col}': numeric_ratio={numeric_ratio:.2f}")
                    
                    if numeric_ratio > 0.5: # Strict threshold: If >50% numeric, it's NOT a name
                         debug_rejections.append(f"Col '{col}' rejected by content (numeric ratio {numeric_ratio:.2f})")
                         continue
                         
                    # Check overlap with ID patterns (uuid, long numbers)
                    if sample.astype(str).str.match(r'^[0-9a-fA-F\-]{10,}$').mean() > 0.5:
                         debug_rejections.append(f"Col '{col}' rejected by UUID pattern")
                         continue
                         
                else:
                    debug_rejections.append(f"Col '{col}' rejected: Empty sample")
            except Exception as e:
                debug_rejections.append(f"Col '{col}' error: {str(e)}")
                pass
            
            # Add to candidates
            item_candidates.append(col)
        else:
             pass
    
    # DEBUG: Show columns and rejections
    # st.write("DEBUG Columns:", df.columns.tolist())
    # st.write("DEBUG Rejections:", debug_rejections)
            
    # 2. T√¨m c·ªôt Price Candidates
    # Th√™m unaccented keywords: 'gia', 'don gia'
    price_keywords = ['price', 'cost', 'amount', 'gi√°', 'ƒë∆°n gi√°', 'chi ph√≠', 'ti·ªÅn', 'gia', 'don gia', 'gia_ban']
    price_candidates = []
    
    for col in df.columns:
        if any(k in col.lower() for k in price_keywords):
             # Price column basic validation
             try:
                if df[col].dtype == 'object':
                     sample = df[col].astype(str).str.replace(r'[^\d]', '', regex=True)
                     valid_count = pd.to_numeric(sample, errors='coerce').notna().sum()
                else:
                     valid_count = df[col].notna().sum()
                
                if valid_count > 0:
                     price_candidates.append(col)
             except:
                continue
                
    # 3. Enhanced Strategy: Coalesce Columns (G·ªôp c·ªôt)
    # V√¨ d·ªØ li·ªáu c√≥ th·ªÉ ƒë·∫øn t·ª´ nhi·ªÅu ngu·ªìn (Menu file d√πng 'Item', Competitor file d√πng 'ten_mon')
    # Ch√∫ng ta s·∫Ω t√¨m c·∫∑p t·ªët nh·∫•t, NH∆ØNG sau ƒë√≥ fillna b·∫±ng c√°c c·∫∑p kh√°c
    
    best_item = None
    best_price = None
    max_overlap = -1
    
    # 3a. Find Best Pair first (as primary)
    for i_col in item_candidates:
        for p_col in price_candidates:
            if i_col == p_col:
                continue
            overlap_count = (df[i_col].notna() & df[p_col].notna()).sum()
            if overlap_count > max_overlap:
                max_overlap = overlap_count
                best_item = i_col
                best_price = p_col
    
    if not best_item or not best_price:
        # Fallback info
        # if hasattr(st, 'warning'):
        #      st.warning(f"Kh√¥ng t√¨m th·∫•y c·∫∑p c·ªôt Item-Price ph√π h·ª£p. Candidates: Item={len(item_candidates)}, Price={len(price_candidates)}")
        return pd.DataFrame()

    # 3b. Create Coalesced Columns
    # Copy data from best pair
    df['_Final_Item'] = df[best_item]
    df['_Final_Price'] = df[best_price]
    
    # Try to fill gaps with other candidates
    # Sort other candidates by overlap density? Or just iterate
    for i_col in item_candidates:
        if i_col != best_item:
             df['_Final_Item'] = df['_Final_Item'].fillna(df[i_col])
             
    for p_col in price_candidates:
        if p_col != best_price:
             # Clean price before coalesce?
             # For simplicity, just coalesce raw values, cleaning happens later
             df['_Final_Price'] = df['_Final_Price'].fillna(df[p_col])
             
    item_col = '_Final_Item'
    price_col = '_Final_Price'
                
    if not item_col or not price_col:
        return pd.DataFrame()
        
    # 3. Clean Price Data
    df_clean = df.copy()
    
    # Convert price to numeric
    # Convert price to numeric
    if df_clean[price_col].dtype == 'object':
        # Handle 'k' suffix (e.g. 25k -> 25000)
        df_clean[price_col] = df_clean[price_col].astype(str).str.lower().str.replace('k', '000')
        
        df_clean[price_col] = pd.to_numeric(
            df_clean[price_col].str.replace(r'[^\d]', '', regex=True), 
            errors='coerce'
        )
    
    # Handle small numbers logic (e.g. 27 -> 27000)
    # If price is small (e.g. < 1000), assume it's in thousands
    if pd.api.types.is_numeric_dtype(df_clean[price_col]):
        df_clean[price_col] = df_clean[price_col].apply(lambda x: x * 1000 if 0 < x < 1000 else x)
    
    df_clean = df_clean.dropna(subset=[item_col, price_col])
    
    # --- 3.5 Heuristic: Override Source based on Item Name ---
    # User feedback: "t√™n sp n√†o c√≥ ten my_shop.... th√¨ l√† c·ªßa m√¨nh"
    # Logic: Check if item name contains keywords, if so, force update Source
    
    # Keywords
    myshop_keywords = r'my_shop|myshop|c·ªßa m√¨nh|my store|shop m√¨nh'
    comp_keywords = r'competitor|ƒë·ªëi th·ªß|th·ªã tr∆∞·ªùng|qu√°n kh√°c'
    
    item_series = df_clean[item_col].astype(str).str.lower()
    
    mask_myshop = item_series.str.contains(myshop_keywords, regex=True)
    if mask_myshop.any():
        df_clean.loc[mask_myshop, 'source'] = 'MY_SHOP'
        
    mask_competitor = item_series.str.contains(comp_keywords, regex=True)
    if mask_competitor.any():
        df_clean.loc[mask_competitor, 'source'] = 'COMPETITOR'
    # ---------------------------------------------------------
    
    # 4. Aggregate
    # Chu·∫©n h√≥a t√™n m√≥n (lowercase, strip)
    df_clean['item_norm'] = df_clean[item_col].astype(str).str.lower().str.strip()
    
    # Calculate avg price per item per source
    if 'source' in df_clean.columns:
        agg = df_clean.groupby(['item_norm', 'source'])[price_col].mean().reset_index()
        # Pivot to get My Shop vs Competitor
        pivot = agg.pivot(index='item_norm', columns='source', values=price_col).reset_index()
    else:
        # If no source, assume all is My Shop
        agg = df_clean.groupby('item_norm')[price_col].mean().reset_index()
        pivot = agg
        pivot['MY_SHOP'] = pivot[price_col]
        
    # Rename columns to match expected format
    result_df = pd.DataFrame()
    result_df['M√≥n'] = pivot['item_norm'].str.title()
    
    # Robust Source Mapping using partial match
    # Pivot columns are the unique values from 'source' column
    pivot_cols = [c for c in pivot.columns if c != 'item_norm']
    
    my_price_col = None
    comp_price_col = None
    
    # 1. Try to find My Shop column
    for col in pivot_cols:
        col_str = str(col).lower()
        if any(freq in col_str for freq in ['my_shop', 'myshop', 'my shop', 'c·ªßa m√¨nh', 'shop', 'store', 'me']):
            if not any(neg in col_str for neg in ['b·∫°n', 'competitor', 'ƒë·ªëi th·ªß', 'other']): # avoid false positives if needed
                 my_price_col = col
                 break
    
    # 2. Try to find Competitor column (STRICT)
    for col in pivot_cols:
        col_str = str(col).lower()
        if col != my_price_col:
            if any(freq in col_str for freq in ['competitor', 'ƒë·ªëi th·ªß', 'th·ªã tr∆∞·ªùng', 'qu√°n kh√°c', 'other']):
                comp_price_col = col
                break
    
    # 3. Fallback strategies
    if not my_price_col and not comp_price_col:
        # If no keywords matched, default to My Shop for the first column
        # Assumption: User uploads their own data first/primarily
        if pivot_cols:
            my_price_col = pivot_cols[0]
            
    elif not my_price_col and comp_price_col:
        # If we have a Competitor column, check if there are others that could be My Shop
        remaining = [c for c in pivot_cols if c != comp_price_col]
        if remaining:
            my_price_col = remaining[0]

    # Assign values
    if my_price_col:
        result_df['Gi√° c·ªßa b·∫°n'] = pivot[my_price_col]
    else:
        result_df['Gi√° c·ªßa b·∫°n'] = 0
        
    if comp_price_col:
        result_df['Gi√° ƒë·ªëi th·ªß'] = pivot[comp_price_col]
    else:
         result_df['Gi√° ƒë·ªëi th·ªß'] = 0
        
    # Fill NaN with 0
    result_df = result_df.fillna(0)
    
    return result_df[['M√≥n', 'Gi√° c·ªßa b·∫°n', 'Gi√° ƒë·ªëi th·ªß']]

def create_price_comparison_chart(price_data: pd.DataFrame):
    """
    T·∫°o bi·ªÉu ƒë·ªì so s√°nh gi√° d·∫°ng Grouped Bar Chart
    
    Args:
        price_data: DataFrame v·ªõi columns ['M√≥n', 'Gi√° c·ªßa b·∫°n', 'Gi√° ƒë·ªëi th·ªß']
    """
    if price_data is None or price_data.empty:
        return None
        
    fig = go.Figure()
    
    # Gi√° c·ªßa b·∫°n
    fig.add_trace(go.Bar(
        x=price_data['M√≥n'],
        y=price_data['Gi√° c·ªßa b·∫°n'],
        name='Gi√° c·ªßa b·∫°n',
        marker_color='#3498db',
        text=price_data['Gi√° c·ªßa b·∫°n'].apply(lambda x: f"{x:,.0f}"),
        textposition='auto'
    ))
    
    # Gi√° ƒë·ªëi th·ªß
    fig.add_trace(go.Bar(
        x=price_data['M√≥n'],
        y=price_data['Gi√° ƒë·ªëi th·ªß'],
        name='Gi√° ƒë·ªëi th·ªß',
        marker_color='#e74c3c',
        text=price_data['Gi√° ƒë·ªëi th·ªß'].apply(lambda x: f"{x:,.0f}"),
        textposition='auto'
    ))
    
    # Calculate % difference for tooltip
    # Safe division
    diff_pct = ((price_data['Gi√° c·ªßa b·∫°n'] - price_data['Gi√° ƒë·ªëi th·ªß']) / price_data['Gi√° ƒë·ªëi th·ªß'].replace(0, 1) * 100).round(1)
    
    fig.update_layout(
        title='So s√°nh Gi√° s·∫£n ph·∫©m',
        xaxis_title='S·∫£n ph·∫©m',
        yaxis_title='Gi√° (VND)',
        barmode='group',
        height=500,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        margin=dict(l=50, r=50, t=80, b=50)
    )
    
    return fig

